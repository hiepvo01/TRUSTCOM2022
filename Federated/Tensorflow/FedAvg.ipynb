{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TUTORIAL](https://colab.research.google.com/github/tensorflow/federated/blob/v0.21.0/docs/tutorials/federated_learning_for_image_classification.ipynb#scrollTo=Q3ynrxd53HzY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data()\n",
    "weights_hid = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLIENTS = 10\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "def preprocess(dataset):\n",
    "\n",
    "  def batch_format_fn(element):\n",
    "    \"\"\"Flatten a batch of EMNIST data and return a (features, label) tuple.\"\"\"\n",
    "    return (tf.reshape(element['pixels'], [-1, 784]), \n",
    "            tf.reshape(element['label'], [-1, 1]))\n",
    "\n",
    "  return dataset.batch(BATCH_SIZE).map(batch_format_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_ids = sorted(emnist_train.client_ids)[:NUM_CLIENTS]\n",
    "federated_train_data = [preprocess(emnist_train.create_tf_dataset_for_client(x))\n",
    "  for x in client_ids\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_keras_model():\n",
    "  initializer = tf.keras.initializers.GlorotNormal(seed=0)\n",
    "  return tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Input(shape=(784,)),\n",
    "      tf.keras.layers.Dense(10, kernel_initializer=initializer),\n",
    "      tf.keras.layers.Softmax(),\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn():\n",
    "  keras_model = create_keras_model()\n",
    "  return tff.learning.from_keras_model(\n",
    "      keras_model,\n",
    "      input_spec=federated_train_data[0].element_spec,\n",
    "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building your own Federated Learning algorithm\n",
    "\n",
    "While the tff.learning API allows one to create many variants of Federated Averaging, there are other federated algorithms that do not fit neatly into this framework. For example, you may want to add regularization, clipping, or more complicated algorithms such as federated GAN training. You may also be instead be interested in federated analytics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these more advanced algorithms, we'll have to write our own custom algorithm using TFF. In many cases, federated algorithms have 4 main components:\n",
    "\n",
    "A server-to-client broadcast step.\n",
    "A local client update step.\n",
    "A client-to-server upload step.\n",
    "A server update step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In TFF, we generally represent federated algorithms as a tff.templates.IterativeProcess (which we refer to as just an IterativeProcess throughout). This is a class that contains initialize and next functions. Here, initialize is used to initialize the server, and next will perform one communication round of the federated algorithm. Let's write a skeleton of what our iterative process for FedAvg should look like.\n",
    "\n",
    "First, we have an initialize function that simply creates a tff.learning.Model, and returns its trainable weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_fn():\n",
    "  model = model_fn()\n",
    "  return model.trainable_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function looks good, but as we will see later, we will need to make a small modification to make it a \"TFF computation\".\n",
    "\n",
    "We also want to sketch the next_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_fn(server_weights, federated_dataset):\n",
    "  # Broadcast the server weights to the clients.\n",
    "  server_weights_at_client = broadcast(server_weights)\n",
    "\n",
    "  # Each client computes their updated weights.\n",
    "  client_weights = client_update(federated_dataset, server_weights_at_client)\n",
    "\n",
    "  # The server averages these updates.\n",
    "  mean_client_weights = mean(client_weights)\n",
    "\n",
    "  # The server updates its model.\n",
    "  server_weights = server_update(mean_client_weights)\n",
    "\n",
    "  return server_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Client Update\n",
    "We will use our tff.learning.Model to do client training in essentially the same way you would train a TensorFlow model. In particular, we will use tf.GradientTape to compute the gradient on batches of data, then apply these gradient using a client_optimizer. We focus only on the trainable weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def client_update(model, dataset, server_weights, client_optimizer):\n",
    "  \"\"\"Performs training (using the server model weights) on the client's dataset.\"\"\"\n",
    "  # Initialize the client model with the current server weights.\n",
    "  client_weights = model.trainable_variables\n",
    "  # Assign the server weights to the client model.\n",
    "  tf.nest.map_structure(lambda x, y: x.assign(y),\n",
    "                        client_weights, server_weights)\n",
    "\n",
    "  # Use the client_optimizer to update the local model.\n",
    "  for batch in dataset:\n",
    "    with tf.GradientTape() as tape:\n",
    "      # Compute a forward pass on the batch of data\n",
    "      outputs = model.forward_pass(batch)\n",
    "\n",
    "    # Compute the corresponding gradient\n",
    "    grads = tape.gradient(outputs.loss, client_weights)\n",
    "    grads_and_vars = zip(grads, client_weights)\n",
    "\n",
    "    # Apply the gradient using a client optimizer.\n",
    "    client_optimizer.apply_gradients(grads_and_vars)\n",
    "  \n",
    "  print(client_weights)\n",
    "\n",
    "  return client_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Server Update\n",
    "The server update for FedAvg is simpler than the client update. We will implement \"vanilla\" federated averaging, in which we simply replace the server model weights by the average of the client model weights. Again, we only focus on the trainable weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def server_update(model, mean_client_weights):\n",
    "  \"\"\"Updates the server model weights as the average of the client model weights.\"\"\"\n",
    "  model_weights = model.trainable_variables\n",
    "  # Assign the mean client weights to the server model.\n",
    "  tf.nest.map_structure(lambda x, y: x.assign(y),\n",
    "                        model_weights, mean_client_weights)\n",
    "  return model_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The snippet could be simplified by simply returning the mean_client_weights. However, more advanced implementations of Federated Averaging use mean_client_weights with more sophisticated techniques, such as momentum or adaptivity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building your own Federated Learning Algorithm\n",
    "Now that we've gotten a glimpse of the Federated Core, we can build our own federated learning algorithm. Remember that above, we defined an initialize_fn and next_fn for our algorithm. The next_fn will make use of the client_update and server_update we defined using pure TensorFlow code.\n",
    "\n",
    "However, in order to make our algorithm a federated computation, we will need both the next_fn and initialize_fn to each be a tff.federated_computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the initialization computation\n",
    "The initialize function will be quite simple: We will create a model using model_fn. However, remember that we must separate out our TensorFlow code using tff.tf_computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tff.tf_computation\n",
    "def server_init():\n",
    "  model = model_fn()\n",
    "  return model.trainable_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then pass this directly into a federated computation using \n",
    "\n",
    "*   List item\n",
    "*   List item\n",
    "\n",
    "`tff.federated_value`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tff.federated_computation\n",
    "def initialize_fn():\n",
    "  return tff.federated_value(server_init(), tff.SERVER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the `next_fn`\n",
    "\n",
    "We now use our client and server update code to write the actual algorithm. We will first turn our `client_update` into a `tff.tf_computation` that accepts a client datasets and server weights, and outputs an updated client weights tensor.\n",
    "\n",
    "We will need the corresponding types to properly decorate our function. Luckily, the type of the server weights can be extracted directly from our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<float32[?,784],int32[?,1]>*\n",
      "<float32[784,10],float32[10]>\n"
     ]
    }
   ],
   "source": [
    "whimsy_model = model_fn()\n",
    "tf_dataset_type = tff.SequenceType(whimsy_model.input_spec)\n",
    "\n",
    "print(str(tf_dataset_type))\n",
    "model_weights_type = server_init.type_signature.result\n",
    "print(model_weights_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'dense/kernel:0' shape=(784, 10) dtype=float32>, <tf.Variable 'dense/bias:0' shape=(10,) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "@tff.tf_computation(tf_dataset_type, model_weights_type)\n",
    "def client_update_fn(tf_dataset, server_weights):\n",
    "  model = model_fn()\n",
    "  client_optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "  return client_update(model, tf_dataset, server_weights, client_optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":The `tff.tf_computation` version of the server update can be defined in a similar way, using types we've already extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello server\n"
     ]
    }
   ],
   "source": [
    "@tff.tf_computation(model_weights_type)\n",
    "def server_update_fn(mean_client_weights):\n",
    "  model = model_fn()\n",
    "  print('hello server')\n",
    "  return server_update(model, mean_client_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last, but not least, we need to create the `tff.federated_computation` that brings this all together. This function will accept two *federated values*, one corresponding to the server weights (with placement `tff.SERVER`), and the other corresponding to the client datasets (with placement `tff.CLIENTS`).\n",
    "\n",
    "Note that both these types were defined above! We simply need to give them the proper placement using `tff.FederatedType`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_server_type = tff.FederatedType(model_weights_type, tff.SERVER)\n",
    "federated_dataset_type = tff.FederatedType(tf_dataset_type, tff.CLIENTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember the 4 elements of an FL algorithm?\n",
    "\n",
    "1. A server-to-client broadcast step.\n",
    "2. A local client update step.\n",
    "3. A client-to-server upload step.\n",
    "4. A server update step.\n",
    "\n",
    "Now that we've built up the above, each part can be compactly represented as a single line of TFF code. This simplicity is why we had to take extra care to specify things such as federated types!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tff.federated_computation(federated_server_type, federated_dataset_type)\n",
    "def next_fn(server_weights, federated_dataset):\n",
    "  # Broadcast the server weights to the clients.\n",
    "  server_weights_at_client = tff.federated_broadcast(server_weights)\n",
    "\n",
    "  # Each client computes their updated weights.\n",
    "  client_weights = tff.federated_map(\n",
    "      client_update_fn, (federated_dataset, server_weights_at_client))\n",
    "  \n",
    "  # The server averages these updates.\n",
    "  mean_client_weights = tff.federated_mean(client_weights)\n",
    "\n",
    "  # The server updates its model.\n",
    "  server_weights = tff.federated_map(server_update_fn, mean_client_weights)\n",
    "\n",
    "  return server_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a tff.federated_computation for both the algorithm initialization, and for running one step of the algorithm. To finish our algorithm, we pass these into tff.templates.IterativeProcess.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_algorithm = tff.templates.IterativeProcess(\n",
    "    initialize_fn=initialize_fn,\n",
    "    next_fn=next_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the algorithm\n",
    "\n",
    "Let's run a few rounds, and see how the loss changes. First, we will define an evaluation function using the centralized approach discussed in the second tutorial.\n",
    "\n",
    "We first create a centralized evaluation dataset, and then apply the same preprocessing we used for the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "central_emnist_test = emnist_test.create_tf_dataset_from_all_clients()\n",
    "central_emnist_test = preprocess(central_emnist_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we write a function that accepts a server state, and uses Keras to evaluate on the test dataset. If you're familiar with `tf.Keras`, this will all look familiar, though note the use of `set_weights`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(server_state):\n",
    "  keras_model = create_keras_model()\n",
    "  keras_model.compile(\n",
    "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]  \n",
    "  )\n",
    "  keras_model.set_weights(server_state)\n",
    "  keras_model.evaluate(central_emnist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2042/2042 [==============================] - 8s 4ms/step - loss: 2.8479 - sparse_categorical_accuracy: 0.1027\n"
     ]
    }
   ],
   "source": [
    "server_state = federated_algorithm.initialize()\n",
    "evaluate(server_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train for a few rounds and see if anything changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for round in range(30):\n",
    "  server_state = federated_algorithm.next(server_state, federated_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2042/2042 [==============================] - 8s 4ms/step - loss: 2.0506 - sparse_categorical_accuracy: 0.3813\n"
     ]
    }
   ],
   "source": [
    "evaluate(server_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00193115 -0.00283541  0.00199257  0.00015633  0.00357123  0.00100648\n",
      " -0.00112897  0.00109023  0.00087481 -0.00279613]\n"
     ]
    }
   ],
   "source": [
    "print((server_state[1]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3afb210fe50ad1836e9c960d622d1338248a5c454d742c389c06a20b52875194"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
