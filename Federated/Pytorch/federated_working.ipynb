{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data.dataset import Dataset \n",
    "from aijack.attack import GradientInversion_Attack\n",
    "from matplotlib import pyplot as plt  \n",
    "torch.backends.cudnn.benchmark=True\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clients = 10\n",
    "num_selected = 10\n",
    "num_rounds = 5\n",
    "epochs = 5\n",
    "batch_size = 3\n",
    "client_victim = 1\n",
    "data = \"MNIST\"\n",
    "chosen_model = ''\n",
    "if data == \"CIFAR10\":\n",
    "    chosen_model = 'test'\n",
    "    channels = 3\n",
    "    norm = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    hideen=768\n",
    "    img_shape = (channels, 32, 32)\n",
    "else:\n",
    "    chosen_model = 'test'\n",
    "    channels = 1\n",
    "    norm = transforms.Normalize((0.5), (0.5))\n",
    "    hideen=588\n",
    "    img_shape = (channels, 28, 28)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "##### Creating desired data distribution among clients  #####\n",
    "#############################################################\n",
    "\n",
    "# Image augmentation \n",
    "transform_train = transforms.Compose([\n",
    "    # transforms.RandomCrop(32, padding=4),\n",
    "    # transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    norm,\n",
    "])\n",
    "\n",
    "# if data == \"CIFAR10\":\n",
    "#     # Loading CIFAR10 using torchvision.datasets\n",
    "#     traindata = datasets.CIFAR10('./data', train=True, download=True,\n",
    "#                         transform= transform_train)\n",
    "# else:\n",
    "#     # Loading CIFAR10 using torchvision.datasets\n",
    "#     traindata = datasets.MNIST('./data', train=True, download=True,\n",
    "#                         transform= transform_train)\n",
    "\n",
    "# # Dividing the training data into num_clients, with each client having equal number of images\n",
    "# # traindata_split = torch.utils.data.random_split(traindata, [int(traindata.data.shape[0] / num_clients) for _ in range(num_clients)])\n",
    "\n",
    "# traindata_split = torch.utils.data.random_split(traindata, [100 for _ in range(600)])\n",
    "# traindata_split = traindata_split[:10]\n",
    "# torch.save(traindata_split, '../../data/MNIST.pth')\n",
    "\n",
    "# Creating a pytorch loader for a Deep Learning model\n",
    "train_loader = [torch.utils.data.DataLoader(x, batch_size=batch_size, shuffle=True) for x in torch.load('../../data/MNIST.pth')]\n",
    "\n",
    "# Normalizing the test images\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    norm,\n",
    "])\n",
    "\n",
    "if data == \"CIFAR10\":\n",
    "    # Loading the test iamges and thus converting them into a test_loader\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "            datasets.CIFAR10('./data', train=False, transform=transform_test\n",
    "            ), batch_size=batch_size, shuffle=True)\n",
    "else:\n",
    "    # Loading the test iamges and thus converting them into a test_loader\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "            datasets.MNIST('./data', train=False, transform=transform_test\n",
    "            ), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bird  cat   dog  \n"
     ]
    }
   ],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader[0])\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "print(images[0].shape)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "##### Neural Network model #####\n",
    "#################################\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, channels=channels, hideen=hideen, num_classes=10):\n",
    "        super(VGG, self).__init__()\n",
    "        self.body = nn.Sequential(\n",
    "            nn.Conv2d(channels, 32, kernel_size=(3,3), stride=(2,2), padding=1),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv2d(32, 64, kernel_size=(3,3), padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv2d(64, 128, kernel_size=(3,3), stride=(2,2), padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv2d(128, 256, kernel_size=(3,3), padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(12544, num_classes)\n",
    "            # nn.Linear(hideen, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.body(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def client_update(client_model, optimizer, train_loader, epoch=5):\n",
    "    \"\"\"\n",
    "    This function updates/trains client model on client data\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    for e in range(epoch):\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            \n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            output = client_model(data)\n",
    "            # loss = F.nll_loss(output, target)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward(retain_graph=True)\n",
    "            \n",
    "            received_gradients = torch.autograd.grad(loss, client_models[i].parameters())\n",
    "            received_gradients = [cg.detach() for cg in received_gradients]\n",
    "                \n",
    "            optimizer.step()\n",
    "    return loss, received_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def server_aggregate(global_model, client_models):\n",
    "    \"\"\"\n",
    "    This function has aggregation method 'mean'\n",
    "    \"\"\"\n",
    "    ### This will take simple mean of the weights of models ###\n",
    "    global_dict = global_model.state_dict()\n",
    "    for k in global_dict.keys():\n",
    "        global_dict[k] = torch.stack([client_models[i].state_dict()[k].float() for i in range(len(client_models))], 0).mean(0)\n",
    "    global_model.load_state_dict(global_dict)\n",
    "    for model in client_models:\n",
    "        model.load_state_dict(global_model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(global_model, test_loader):\n",
    "    \"\"\"This function test the global model on test data and returns test loss and test accuracy \"\"\"\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            output = global_model(data)\n",
    "            # test_loss += F.nll_loss(output, target).item() # sum up batch loss\n",
    "            test_loss += criterion(output, target).item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    acc = correct / len(test_loader.dataset)\n",
    "\n",
    "    return test_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "#### Initializing models and optimizer  ####\n",
    "############################################\n",
    "\n",
    "#### global model ##########\n",
    "global_model =  VGG().cuda()\n",
    "\n",
    "############## client models ##############\n",
    "client_models = [ VGG().cuda() for _ in range(num_selected)]\n",
    "for model in client_models:\n",
    "    model.load_state_dict(global_model.state_dict()) ### initial synchronizing with global model \n",
    "\n",
    "############### optimizers ################\n",
    "opt = [optim.SGD(model.parameters(), lr=0.1) for model in client_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-th round\n",
      "average train loss 13.3 | test loss 0.886 | test acc: 0.134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-th round\n",
      "average train loss 3.42 | test loss 0.427 | test acc: 0.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-th round\n",
      "average train loss 1.55 | test loss 0.283 | test acc: 0.722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-th round\n",
      "average train loss 2.97 | test loss 0.214 | test acc: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4-th round\n",
      "average train loss 2.26 | test loss 0.21 | test acc: 0.809\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "###### List containing info about learning #########\n",
    "losses_train = []\n",
    "losses_test = []\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "# Runnining FL\n",
    "\n",
    "victim_count = 0 \n",
    "for r in range(num_rounds):\n",
    "    # select random clients\n",
    "    client_idx = np.random.permutation(num_clients)[:num_selected]\n",
    "    # client update\n",
    "    loss = 0\n",
    "    \n",
    "    for i in tqdm(range(num_selected)):\n",
    "        client_loss, received_gradients = client_update(client_models[i], opt[i], train_loader[client_idx[i]], epoch=1)\n",
    "        loss += client_loss.item()\n",
    "        \n",
    "    losses_train.append(loss)\n",
    "    # server aggregate\n",
    "    server_aggregate(global_model, client_models)\n",
    "    \n",
    "    test_loss, acc = test(global_model, test_loader)\n",
    "    losses_test.append(test_loss)\n",
    "    acc_test.append(acc)\n",
    "    print('%d-th round' % r)\n",
    "    print('average train loss %0.3g | test loss %0.3g | test acc: %0.3f' % (loss / num_selected, test_loss, acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 12544])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0166,  0.0200,  0.0025,  ..., -0.0049,  0.0124, -0.0330],\n",
       "        [-0.0045, -0.0117, -0.0031,  ...,  0.0417, -0.0064, -0.0070],\n",
       "        [ 0.0115, -0.0134, -0.0028,  ..., -0.0393, -0.0112,  0.0355],\n",
       "        ...,\n",
       "        [-0.0182,  0.0063, -0.0040,  ...,  0.0246,  0.0137, -0.0066],\n",
       "        [-0.0185,  0.0080,  0.0606,  ..., -0.0118, -0.0473,  0.0012],\n",
       "        [-0.0026,  0.0253, -0.0047,  ...,  0.0225,  0.0361, -0.0088]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(global_model.fc[0].weight.shape)\n",
    "global_model.fc[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'body.0.weight': (torch.float32, torch.Size([32, 1, 3, 3])),\n",
       " 'body.0.bias': (torch.float32, torch.Size([32])),\n",
       " 'body.3.weight': (torch.float32, torch.Size([64, 32, 3, 3])),\n",
       " 'body.3.bias': (torch.float32, torch.Size([64])),\n",
       " 'body.4.weight': (torch.float32, torch.Size([64])),\n",
       " 'body.4.bias': (torch.float32, torch.Size([64])),\n",
       " 'body.4.running_mean': (torch.float32, torch.Size([64])),\n",
       " 'body.4.running_var': (torch.float32, torch.Size([64])),\n",
       " 'body.4.num_batches_tracked': (torch.int64, torch.Size([])),\n",
       " 'body.7.weight': (torch.float32, torch.Size([128, 64, 3, 3])),\n",
       " 'body.7.bias': (torch.float32, torch.Size([128])),\n",
       " 'body.8.weight': (torch.float32, torch.Size([128])),\n",
       " 'body.8.bias': (torch.float32, torch.Size([128])),\n",
       " 'body.8.running_mean': (torch.float32, torch.Size([128])),\n",
       " 'body.8.running_var': (torch.float32, torch.Size([128])),\n",
       " 'body.8.num_batches_tracked': (torch.int64, torch.Size([])),\n",
       " 'body.11.weight': (torch.float32, torch.Size([256, 128, 3, 3])),\n",
       " 'body.11.bias': (torch.float32, torch.Size([256])),\n",
       " 'body.12.weight': (torch.float32, torch.Size([256])),\n",
       " 'body.12.bias': (torch.float32, torch.Size([256])),\n",
       " 'body.12.running_mean': (torch.float32, torch.Size([256])),\n",
       " 'body.12.running_var': (torch.float32, torch.Size([256])),\n",
       " 'body.12.num_batches_tracked': (torch.int64, torch.Size([])),\n",
       " 'fc.0.weight': (torch.float32, torch.Size([10, 12544])),\n",
       " 'fc.0.bias': (torch.float32, torch.Size([10]))}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: (v.dtype, v.shape) for k, v in global_model.state_dict().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 1, 3, 3)\n",
      "(64, 32, 3, 3)\n",
      "(128, 64, 3, 3)\n",
      "(256, 128, 3, 3)\n",
      "(12544, 10)\n"
     ]
    }
   ],
   "source": [
    "torch_weights = global_model.body.state_dict()\n",
    "# Reshape weights for Keras model\n",
    "keras_weights = [w.cpu().numpy() for w in torch_weights.values()]\n",
    "\n",
    "for i in [0, 2, 9, 16]:\n",
    "    print(keras_weights[i].shape)\n",
    "    # conv2d layer: Torch (out,in,h,w) Keras (h,w,in,out)\n",
    "    keras_weights[i] = np.moveaxis(keras_weights[i], [0,1], [-1,-2])\n",
    "\n",
    "keras_weights.append(global_model.fc[0].weight.cpu().detach().numpy().T)\n",
    "print(keras_weights[len(keras_weights)-1].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(global_model, \"../../pretrained/test_torch.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 1, 3, 3)\n",
      "(64, 32, 3, 3)\n",
      "(128, 64, 3, 3)\n",
      "(256, 128, 3, 3)\n",
      "(12544, 10)\n"
     ]
    }
   ],
   "source": [
    "torch_model = torch.load(\"../../pretrained/test_torch.pt\")\n",
    "torch_weights = torch_model.body.state_dict()\n",
    "# Reshape weights for Keras model\n",
    "keras_weights = [w.cpu().numpy() for w in torch_weights.values()]\n",
    "\n",
    "for i in [0, 2, 9, 16]:\n",
    "    print(keras_weights[i].shape)\n",
    "    # conv2d layer: Torch (out,in,h,w) Keras (h,w,in,out)\n",
    "    keras_weights[i] = np.moveaxis(keras_weights[i], [0,1], [-1,-2])\n",
    "keras_weights.append(torch_model.fc[0].weight.cpu().detach().numpy().T)\n",
    "print(keras_weights[len(keras_weights)-1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras_weights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Projects\\TRUSTCOM2022\\Federated\\Pytorch\\federated_working.ipynb Cell 16'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Projects/TRUSTCOM2022/Federated/Pytorch/federated_working.ipynb#ch0000015?line=0'>1</a>\u001b[0m new_keras \u001b[39m=\u001b[39m [v \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m keras_weights \u001b[39mif\u001b[39;00m v\u001b[39m.\u001b[39mshape \u001b[39m!=\u001b[39m ()]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/TRUSTCOM2022/Federated/Pytorch/federated_working.ipynb#ch0000015?line=1'>2</a>\u001b[0m \u001b[39mlen\u001b[39m(new_keras)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'keras_weights' is not defined"
     ]
    }
   ],
   "source": [
    "new_keras = [v for v in keras_weights if v.shape != ()]\n",
    "len(new_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "968934d88acb7fa4003ed11a52074e68ba95c397f9757dc45b04b92654f10ea7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
