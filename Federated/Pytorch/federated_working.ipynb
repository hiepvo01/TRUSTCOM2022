{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data.dataset import Dataset \n",
    "from aijack.attack import GradientInversion_Attack\n",
    "from matplotlib import pyplot as plt  \n",
    "torch.backends.cudnn.benchmark=True\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clients = 10\n",
    "num_selected = 10\n",
    "num_rounds = 5\n",
    "epochs = 5\n",
    "batch_size = 3\n",
    "client_victim = 1\n",
    "data = \"MNIST\"\n",
    "chosen_model = ''\n",
    "if data == \"CIFAR10\":\n",
    "    chosen_model = 'test'\n",
    "    channels = 3\n",
    "    norm = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    hideen=768\n",
    "    img_shape = (channels, 32, 32)\n",
    "else:\n",
    "    chosen_model = 'test'\n",
    "    channels = 1\n",
    "    norm = transforms.Normalize((0.5), (0.5))\n",
    "    hideen=588\n",
    "    img_shape = (channels, 28, 28)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "##### Creating desired data distribution among clients  #####\n",
    "#############################################################\n",
    "\n",
    "# Image augmentation \n",
    "transform_train = transforms.Compose([\n",
    "    # transforms.RandomCrop(32, padding=4),\n",
    "    # transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    norm,\n",
    "])\n",
    "\n",
    "# if data == \"CIFAR10\":\n",
    "#     # Loading CIFAR10 using torchvision.datasets\n",
    "#     traindata = datasets.CIFAR10('./data', train=True, download=True,\n",
    "#                         transform= transform_train)\n",
    "# else:\n",
    "#     # Loading CIFAR10 using torchvision.datasets\n",
    "#     traindata = datasets.MNIST('./data', train=True, download=True,\n",
    "#                         transform= transform_train)\n",
    "\n",
    "# # Dividing the training data into num_clients, with each client having equal number of images\n",
    "# # traindata_split = torch.utils.data.random_split(traindata, [int(traindata.data.shape[0] / num_clients) for _ in range(num_clients)])\n",
    "\n",
    "# traindata_split = torch.utils.data.random_split(traindata, [100 for _ in range(600)])\n",
    "# traindata_split = traindata_split[:10]\n",
    "# torch.save(traindata_split, '../../data/MNIST.pth')\n",
    "\n",
    "# Creating a pytorch loader for a Deep Learning model\n",
    "train_loader = [torch.utils.data.DataLoader(x, batch_size=batch_size, shuffle=True) for x in torch.load('../../data/MNIST.pth')]\n",
    "\n",
    "# Normalizing the test images\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    norm,\n",
    "])\n",
    "\n",
    "if data == \"CIFAR10\":\n",
    "    # Loading the test iamges and thus converting them into a test_loader\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "            datasets.CIFAR10('./data', train=False, transform=transform_test\n",
    "            ), batch_size=batch_size, shuffle=True)\n",
    "else:\n",
    "    # Loading the test iamges and thus converting them into a test_loader\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "            datasets.MNIST('./data', train=False, transform=transform_test\n",
    "            ), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plane dog   dog  \n"
     ]
    }
   ],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader[0])\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "##### Neural Network model #####\n",
    "#################################\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, channels=channels, hideen=hideen, num_classes=10):\n",
    "        super(VGG, self).__init__()\n",
    "        self.body = nn.Sequential(\n",
    "            nn.Conv2d(channels, 32, kernel_size=(3,3), stride=(2,2), padding=1),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv2d(32, 64, kernel_size=(3,3), padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv2d(64, 128, kernel_size=(3,3), stride=(2,2), padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv2d(128, 256, kernel_size=(3,3), padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(12544, num_classes)\n",
    "            # nn.Linear(hideen, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.body(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def client_update(client_model, optimizer, train_loader, epoch=5):\n",
    "    \"\"\"\n",
    "    This function updates/trains client model on client data\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    for e in range(epoch):\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            \n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            output = client_model(data)\n",
    "            # loss = F.nll_loss(output, target)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward(retain_graph=True)\n",
    "            \n",
    "            received_gradients = torch.autograd.grad(loss, client_models[i].parameters())\n",
    "            received_gradients = [cg.detach() for cg in received_gradients]\n",
    "                \n",
    "            optimizer.step()\n",
    "    return loss, received_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def server_aggregate(global_model, client_models):\n",
    "    \"\"\"\n",
    "    This function has aggregation method 'mean'\n",
    "    \"\"\"\n",
    "    ### This will take simple mean of the weights of models ###\n",
    "    global_dict = global_model.state_dict()\n",
    "    for k in global_dict.keys():\n",
    "        global_dict[k] = torch.stack([client_models[i].state_dict()[k].float() for i in range(len(client_models))], 0).mean(0)\n",
    "    global_model.load_state_dict(global_dict)\n",
    "    for model in client_models:\n",
    "        model.load_state_dict(global_model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(global_model, test_loader):\n",
    "    \"\"\"This function test the global model on test data and returns test loss and test accuracy \"\"\"\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            output = global_model(data)\n",
    "            # test_loss += F.nll_loss(output, target).item() # sum up batch loss\n",
    "            test_loss += criterion(output, target).item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    acc = correct / len(test_loader.dataset)\n",
    "\n",
    "    return test_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "#### Initializing models and optimizer  ####\n",
    "############################################\n",
    "\n",
    "#### global model ##########\n",
    "global_model =  VGG().cuda()\n",
    "\n",
    "############## client models ##############\n",
    "client_models = [ VGG().cuda() for _ in range(num_selected)]\n",
    "for model in client_models:\n",
    "    model.load_state_dict(global_model.state_dict()) ### initial synchronizing with global model \n",
    "\n",
    "############### optimizers ################\n",
    "opt = [optim.SGD(model.parameters(), lr=0.1) for model in client_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-th round\n",
      "average train loss 13.3 | test loss 0.886 | test acc: 0.134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-th round\n",
      "average train loss 3.42 | test loss 0.427 | test acc: 0.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-th round\n",
      "average train loss 1.55 | test loss 0.283 | test acc: 0.722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-th round\n",
      "average train loss 2.97 | test loss 0.214 | test acc: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4-th round\n",
      "average train loss 2.26 | test loss 0.21 | test acc: 0.809\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "###### List containing info about learning #########\n",
    "losses_train = []\n",
    "losses_test = []\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "# Runnining FL\n",
    "\n",
    "victim_count = 0 \n",
    "for r in range(num_rounds):\n",
    "    # select random clients\n",
    "    client_idx = np.random.permutation(num_clients)[:num_selected]\n",
    "    # client update\n",
    "    loss = 0\n",
    "    \n",
    "    for i in tqdm(range(num_selected)):\n",
    "        client_loss, received_gradients = client_update(client_models[i], opt[i], train_loader[client_idx[i]], epoch=1)\n",
    "        loss += client_loss.item()\n",
    "        \n",
    "    losses_train.append(loss)\n",
    "    # server aggregate\n",
    "    server_aggregate(global_model, client_models)\n",
    "    \n",
    "    test_loss, acc = test(global_model, test_loader)\n",
    "    losses_test.append(test_loss)\n",
    "    acc_test.append(acc)\n",
    "    print('%d-th round' % r)\n",
    "    print('average train loss %0.3g | test loss %0.3g | test acc: %0.3f' % (loss / num_selected, test_loss, acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 12544])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0166,  0.0200,  0.0025,  ..., -0.0049,  0.0124, -0.0330],\n",
       "        [-0.0045, -0.0117, -0.0031,  ...,  0.0417, -0.0064, -0.0070],\n",
       "        [ 0.0115, -0.0134, -0.0028,  ..., -0.0393, -0.0112,  0.0355],\n",
       "        ...,\n",
       "        [-0.0182,  0.0063, -0.0040,  ...,  0.0246,  0.0137, -0.0066],\n",
       "        [-0.0185,  0.0080,  0.0606,  ..., -0.0118, -0.0473,  0.0012],\n",
       "        [-0.0026,  0.0253, -0.0047,  ...,  0.0225,  0.0361, -0.0088]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(global_model.fc[0].weight.shape)\n",
    "global_model.fc[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'body.0.weight': (torch.float32, torch.Size([32, 1, 3, 3])),\n",
       " 'body.0.bias': (torch.float32, torch.Size([32])),\n",
       " 'body.3.weight': (torch.float32, torch.Size([64, 32, 3, 3])),\n",
       " 'body.3.bias': (torch.float32, torch.Size([64])),\n",
       " 'body.4.weight': (torch.float32, torch.Size([64])),\n",
       " 'body.4.bias': (torch.float32, torch.Size([64])),\n",
       " 'body.4.running_mean': (torch.float32, torch.Size([64])),\n",
       " 'body.4.running_var': (torch.float32, torch.Size([64])),\n",
       " 'body.4.num_batches_tracked': (torch.int64, torch.Size([])),\n",
       " 'body.7.weight': (torch.float32, torch.Size([128, 64, 3, 3])),\n",
       " 'body.7.bias': (torch.float32, torch.Size([128])),\n",
       " 'body.8.weight': (torch.float32, torch.Size([128])),\n",
       " 'body.8.bias': (torch.float32, torch.Size([128])),\n",
       " 'body.8.running_mean': (torch.float32, torch.Size([128])),\n",
       " 'body.8.running_var': (torch.float32, torch.Size([128])),\n",
       " 'body.8.num_batches_tracked': (torch.int64, torch.Size([])),\n",
       " 'body.11.weight': (torch.float32, torch.Size([256, 128, 3, 3])),\n",
       " 'body.11.bias': (torch.float32, torch.Size([256])),\n",
       " 'body.12.weight': (torch.float32, torch.Size([256])),\n",
       " 'body.12.bias': (torch.float32, torch.Size([256])),\n",
       " 'body.12.running_mean': (torch.float32, torch.Size([256])),\n",
       " 'body.12.running_var': (torch.float32, torch.Size([256])),\n",
       " 'body.12.num_batches_tracked': (torch.int64, torch.Size([])),\n",
       " 'fc.0.weight': (torch.float32, torch.Size([10, 12544])),\n",
       " 'fc.0.bias': (torch.float32, torch.Size([10]))}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: (v.dtype, v.shape) for k, v in global_model.state_dict().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 1, 3, 3)\n",
      "(64, 32, 3, 3)\n",
      "(128, 64, 3, 3)\n",
      "(256, 128, 3, 3)\n",
      "(12544, 10)\n"
     ]
    }
   ],
   "source": [
    "torch_weights = global_model.body.state_dict()\n",
    "# Reshape weights for Keras model\n",
    "keras_weights = [w.cpu().numpy() for w in torch_weights.values()]\n",
    "\n",
    "for i in [0, 2, 9, 16]:\n",
    "    print(keras_weights[i].shape)\n",
    "    # conv2d layer: Torch (out,in,h,w) Keras (h,w,in,out)\n",
    "    keras_weights[i] = np.moveaxis(keras_weights[i], [0,1], [-1,-2])\n",
    "keras_weights.append(global_model.fc[0].weight.cpu().detach().numpy().T)\n",
    "print(keras_weights[len(keras_weights)-1].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(global_model, \"../../pretrained/test_torch.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 1, 3, 3)\n",
      "(64, 32, 3, 3)\n",
      "(128, 64, 3, 3)\n",
      "(256, 128, 3, 3)\n",
      "(12544, 10)\n"
     ]
    }
   ],
   "source": [
    "torch_model = torch.load(\"../../pretrained/test_torch.pt\")\n",
    "torch_weights = torch_model.body.state_dict()\n",
    "# Reshape weights for Keras model\n",
    "keras_weights = [w.cpu().numpy() for w in torch_weights.values()]\n",
    "\n",
    "for i in [0, 2, 9, 16]:\n",
    "    print(keras_weights[i].shape)\n",
    "    # conv2d layer: Torch (out,in,h,w) Keras (h,w,in,out)\n",
    "    keras_weights[i] = np.moveaxis(keras_weights[i], [0,1], [-1,-2])\n",
    "keras_weights.append(torch_model.fc[0].weight.cpu().detach().numpy().T)\n",
    "print(keras_weights[len(keras_weights)-1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "968934d88acb7fa4003ed11a52074e68ba95c397f9757dc45b04b92654f10ea7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
