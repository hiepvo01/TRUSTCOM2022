{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data.dataset import Dataset \n",
    "from aijack.attack import GradientInversion_Attack\n",
    "from matplotlib import pyplot as plt  \n",
    "torch.backends.cudnn.benchmark=True\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clients = 10\n",
    "num_selected = 10\n",
    "num_rounds = 5\n",
    "epochs = 5\n",
    "batch_size = 3\n",
    "client_victim = 1\n",
    "data = \"MNIST\"\n",
    "chosen_model = ''\n",
    "if data == \"CIFAR10\":\n",
    "    chosen_model = 'test'\n",
    "    channels = 3\n",
    "    norm = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    hideen=768\n",
    "    img_shape = (channels, 32, 32)\n",
    "else:\n",
    "    chosen_model = 'test'\n",
    "    channels = 1\n",
    "    norm = transforms.Normalize((0.5), (0.5))\n",
    "    hideen=588\n",
    "    img_shape = (channels, 28, 28)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "##### Creating desired data distribution among clients  #####\n",
    "#############################################################\n",
    "\n",
    "# Image augmentation \n",
    "transform_train = transforms.Compose([\n",
    "    # transforms.RandomCrop(32, padding=4),\n",
    "    # transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    norm,\n",
    "])\n",
    "\n",
    "# if data == \"CIFAR10\":\n",
    "#     # Loading CIFAR10 using torchvision.datasets\n",
    "#     traindata = datasets.CIFAR10('./data', train=True, download=True,\n",
    "#                         transform= transform_train)\n",
    "# else:\n",
    "#     # Loading CIFAR10 using torchvision.datasets\n",
    "#     traindata = datasets.MNIST('./data', train=True, download=True,\n",
    "#                         transform= transform_train)\n",
    "\n",
    "# # Dividing the training data into num_clients, with each client having equal number of images\n",
    "# # traindata_split = torch.utils.data.random_split(traindata, [int(traindata.data.shape[0] / num_clients) for _ in range(num_clients)])\n",
    "\n",
    "# traindata_split = torch.utils.data.random_split(traindata, [100 for _ in range(600)])\n",
    "# traindata_split = traindata_split[:10]\n",
    "# torch.save(traindata_split, '../../data/MNIST.pth')\n",
    "\n",
    "# Creating a pytorch loader for a Deep Learning model\n",
    "train_loader = [torch.utils.data.DataLoader(x, batch_size=batch_size, shuffle=True) for x in torch.load('../../data/MNIST.pth')]\n",
    "\n",
    "# Normalizing the test images\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    norm,\n",
    "])\n",
    "\n",
    "if data == \"CIFAR10\":\n",
    "    # Loading the test iamges and thus converting them into a test_loader\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "            datasets.CIFAR10('./data', train=False, transform=transform_test\n",
    "            ), batch_size=batch_size, shuffle=True)\n",
    "else:\n",
    "    # Loading the test iamges and thus converting them into a test_loader\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "            datasets.MNIST('./data', train=False, transform=transform_test\n",
    "            ), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ship  plane dog  \n"
     ]
    }
   ],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader[0])\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "print(images[0].shape)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "##### Neural Network model #####\n",
    "#################################\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, channels=channels, hideen=hideen, num_classes=10):\n",
    "        super(VGG, self).__init__()\n",
    "        self.body = nn.Sequential(\n",
    "            nn.Conv2d(channels, 32, kernel_size=(3,3), stride=(2,2), padding=1),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv2d(32, 64, kernel_size=(3,3), padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv2d(64, 128, kernel_size=(3,3), stride=(2,2), padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv2d(128, 256, kernel_size=(3,3), padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(12544, num_classes)\n",
    "            # nn.Linear(hideen, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.body(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def client_update(client_model, optimizer, train_loader, epoch=5):\n",
    "    \"\"\"\n",
    "    This function updates/trains client model on client data\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    for e in range(epoch):\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            \n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            output = client_model(data)\n",
    "            # loss = F.nll_loss(output, target)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward(retain_graph=True)\n",
    "            \n",
    "            received_gradients = torch.autograd.grad(loss, client_models[i].parameters())\n",
    "            received_gradients = [cg.detach() for cg in received_gradients]\n",
    "            \n",
    "            gradinversion = GradientInversion_Attack(client_models[i], (1, 28, 28), num_iteration=1000,\n",
    "                                                lr=1e2, log_interval=0,\n",
    "                                                optimizer_class=torch.optim.SGD,\n",
    "                                                distancename=\"l2\", optimize_label=False,\n",
    "                                                bn_reg_layers=[client_models[i].body[4], client_models[i].body[8], client_models[i].body[12]],\n",
    "                                                group_num = 3,\n",
    "                                                tv_reg_coef=0.00, l2_reg_coef=0.0001,\n",
    "                                                bn_reg_coef=0.001, gc_reg_coef=0.001, device=device)\n",
    "\n",
    "            result = gradinversion.group_attack(received_gradients, batch_size=batch_size)\n",
    "\n",
    "            fig = plt.figure()\n",
    "            for bid in range(batch_size):\n",
    "                test_img = torch.from_numpy(((sum(result[0]) / len(result[0])).cpu().detach().numpy()[bid]))\n",
    "                img1 = test_img.swapaxes(0,1)\n",
    "                img1 = img1.swapaxes(1,2)\n",
    "                plt.imshow(torchvision.utils.make_grid(img1))\n",
    "                plt.savefig('output/batch'+batch_idx+'.png')\n",
    "\n",
    "            #     ax1 = fig.add_subplot(2, batch_size, bid+1)\n",
    "            #     ax1.imshow(torchvision.utils.make_grid(img1))\n",
    "            #     ax1.set_title(result[1][0][bid].item())\n",
    "            #     ax1.axis(\"off\")\n",
    "            #     ax2 = fig.add_subplot(2, batch_size, batch_size+bid+1)\n",
    "            #     ax2.imshow((sum(result[0]) / len(result[0])).cpu().detach().numpy()[bid][0], cmap=\"gray\")\n",
    "            #     ax2.axis(\"off\")\n",
    "\n",
    "            # plt.suptitle(\"Result of GradInversion\")\n",
    "            \n",
    "                \n",
    "            optimizer.step()\n",
    "    return loss, received_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def server_aggregate(global_model, client_models):\n",
    "    \"\"\"\n",
    "    This function has aggregation method 'mean'\n",
    "    \"\"\"\n",
    "    ### This will take simple mean of the weights of models ###\n",
    "    global_dict = global_model.state_dict()\n",
    "    for k in global_dict.keys():\n",
    "        global_dict[k] = torch.stack([client_models[i].state_dict()[k].float() for i in range(len(client_models))], 0).mean(0)\n",
    "    global_model.load_state_dict(global_dict)\n",
    "    for model in client_models:\n",
    "        model.load_state_dict(global_model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(global_model, test_loader):\n",
    "    \"\"\"This function test the global model on test data and returns test loss and test accuracy \"\"\"\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            output = global_model(data)\n",
    "            # test_loss += F.nll_loss(output, target).item() # sum up batch loss\n",
    "            test_loss += criterion(output, target).item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    acc = correct / len(test_loader.dataset)\n",
    "\n",
    "    return test_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "#### Initializing models and optimizer  ####\n",
    "############################################\n",
    "\n",
    "#### global model ##########\n",
    "global_model =  VGG().cuda()\n",
    "\n",
    "############## client models ##############\n",
    "client_models = [ VGG().cuda() for _ in range(num_selected)]\n",
    "for model in client_models:\n",
    "    model.load_state_dict(global_model.state_dict()) ### initial synchronizing with global model \n",
    "\n",
    "############### optimizers ################\n",
    "opt = [optim.SGD(model.parameters(), lr=0.1) for model in client_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:15<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 4.00 GiB total capacity; 3.46 GiB already allocated; 0 bytes free; 3.49 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\Projects\\TRUSTCOM2022\\Federated\\Pytorch\\federated_working.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/TRUSTCOM2022/Federated/Pytorch/federated_working.ipynb#ch0000009?line=14'>15</a>\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/TRUSTCOM2022/Federated/Pytorch/federated_working.ipynb#ch0000009?line=16'>17</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(num_selected)):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Projects/TRUSTCOM2022/Federated/Pytorch/federated_working.ipynb#ch0000009?line=17'>18</a>\u001b[0m     client_loss, received_gradients \u001b[39m=\u001b[39m client_update(client_models[i], opt[i], train_loader[client_idx[i]], epoch\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/TRUSTCOM2022/Federated/Pytorch/federated_working.ipynb#ch0000009?line=18'>19</a>\u001b[0m     loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m client_loss\u001b[39m.\u001b[39mitem()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/TRUSTCOM2022/Federated/Pytorch/federated_working.ipynb#ch0000009?line=20'>21</a>\u001b[0m losses_train\u001b[39m.\u001b[39mappend(loss)\n",
      "\u001b[1;32md:\\Projects\\TRUSTCOM2022\\Federated\\Pytorch\\federated_working.ipynb Cell 6'\u001b[0m in \u001b[0;36mclient_update\u001b[1;34m(client_model, optimizer, train_loader, epoch)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/TRUSTCOM2022/Federated/Pytorch/federated_working.ipynb#ch0000005?line=16'>17</a>\u001b[0m received_gradients \u001b[39m=\u001b[39m [cg\u001b[39m.\u001b[39mdetach() \u001b[39mfor\u001b[39;00m cg \u001b[39min\u001b[39;00m received_gradients]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/TRUSTCOM2022/Federated/Pytorch/federated_working.ipynb#ch0000005?line=18'>19</a>\u001b[0m gradinversion \u001b[39m=\u001b[39m GradientInversion_Attack(client_models[i], (\u001b[39m1\u001b[39m, \u001b[39m28\u001b[39m, \u001b[39m28\u001b[39m), num_iteration\u001b[39m=\u001b[39m\u001b[39m400\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/TRUSTCOM2022/Federated/Pytorch/federated_working.ipynb#ch0000005?line=19'>20</a>\u001b[0m                                     lr\u001b[39m=\u001b[39m\u001b[39m1e2\u001b[39m, log_interval\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/TRUSTCOM2022/Federated/Pytorch/federated_working.ipynb#ch0000005?line=20'>21</a>\u001b[0m                                     optimizer_class\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mSGD,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/TRUSTCOM2022/Federated/Pytorch/federated_working.ipynb#ch0000005?line=24'>25</a>\u001b[0m                                     tv_reg_coef\u001b[39m=\u001b[39m\u001b[39m0.00\u001b[39m, l2_reg_coef\u001b[39m=\u001b[39m\u001b[39m0.0001\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/TRUSTCOM2022/Federated/Pytorch/federated_working.ipynb#ch0000005?line=25'>26</a>\u001b[0m                                     bn_reg_coef\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m, gc_reg_coef\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m, device\u001b[39m=\u001b[39mdevice)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Projects/TRUSTCOM2022/Federated/Pytorch/federated_working.ipynb#ch0000005?line=27'>28</a>\u001b[0m result \u001b[39m=\u001b[39m gradinversion\u001b[39m.\u001b[39;49mgroup_attack(received_gradients, batch_size\u001b[39m=\u001b[39;49mbatch_size)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/TRUSTCOM2022/Federated/Pytorch/federated_working.ipynb#ch0000005?line=29'>30</a>\u001b[0m fig \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mfigure()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/TRUSTCOM2022/Federated/Pytorch/federated_working.ipynb#ch0000005?line=30'>31</a>\u001b[0m \u001b[39mfor\u001b[39;00m bid \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(batch_size):\n",
      "File \u001b[1;32md:\\Projects\\TRUSTCOM2022\\Federated\\Pytorch\\aijack\\attack\\inversion\\gradientinversion.py:528\u001b[0m, in \u001b[0;36mGradientInversion_Attack.group_attack\u001b[1;34m(self, received_gradients, batch_size)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/Federated/Pytorch/aijack/attack/inversion/gradientinversion.py?line=520'>521</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset_seed(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroup_seed[worker_id])\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/Federated/Pytorch/aijack/attack/inversion/gradientinversion.py?line=521'>522</a>\u001b[0m closure \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setup_closure(\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/Federated/Pytorch/aijack/attack/inversion/gradientinversion.py?line=522'>523</a>\u001b[0m     group_optimizer[worker_id],\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/Federated/Pytorch/aijack/attack/inversion/gradientinversion.py?line=523'>524</a>\u001b[0m     group_fake_x[worker_id],\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/Federated/Pytorch/aijack/attack/inversion/gradientinversion.py?line=524'>525</a>\u001b[0m     group_fake_label[worker_id],\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/Federated/Pytorch/aijack/attack/inversion/gradientinversion.py?line=525'>526</a>\u001b[0m     received_gradients,\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/Federated/Pytorch/aijack/attack/inversion/gradientinversion.py?line=526'>527</a>\u001b[0m )\n\u001b[1;32m--> <a href='file:///d%3A/Projects/TRUSTCOM2022/Federated/Pytorch/aijack/attack/inversion/gradientinversion.py?line=527'>528</a>\u001b[0m distance \u001b[39m=\u001b[39m group_optimizer[worker_id]\u001b[39m.\u001b[39;49mstep(closure)\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/Federated/Pytorch/aijack/attack/inversion/gradientinversion.py?line=529'>530</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_loss:\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/Federated/Pytorch/aijack/attack/inversion/gradientinversion.py?line=530'>531</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_loss[worker_id]\u001b[39m.\u001b[39mappend(distance)\n",
      "File \u001b[1;32md:\\Projects\\TRUSTCOM2022\\.venv\\lib\\site-packages\\torch\\optim\\optimizer.py:88\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/optim/optimizer.py?line=85'>86</a>\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[0;32m     <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/optim/optimizer.py?line=86'>87</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m---> <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/optim/optimizer.py?line=87'>88</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\Projects\\TRUSTCOM2022\\.venv\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/autograd/grad_mode.py?line=23'>24</a>\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m     <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/autograd/grad_mode.py?line=24'>25</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/autograd/grad_mode.py?line=25'>26</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[1;32m---> <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/autograd/grad_mode.py?line=26'>27</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\Projects\\TRUSTCOM2022\\.venv\\lib\\site-packages\\torch\\optim\\sgd.py:120\u001b[0m, in \u001b[0;36mSGD.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/optim/sgd.py?line=117'>118</a>\u001b[0m \u001b[39mif\u001b[39;00m closure \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/optim/sgd.py?line=118'>119</a>\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39menable_grad():\n\u001b[1;32m--> <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/optim/sgd.py?line=119'>120</a>\u001b[0m         loss \u001b[39m=\u001b[39m closure()\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/optim/sgd.py?line=121'>122</a>\u001b[0m \u001b[39mfor\u001b[39;00m group \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_groups:\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/optim/sgd.py?line=122'>123</a>\u001b[0m     params_with_grad \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32md:\\Projects\\TRUSTCOM2022\\Federated\\Pytorch\\aijack\\attack\\inversion\\gradientinversion.py:371\u001b[0m, in \u001b[0;36mGradientInversion_Attack._setup_closure.<locals>.closure\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/Federated/Pytorch/aijack/attack/inversion/gradientinversion.py?line=359'>360</a>\u001b[0m distance \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistancefunc(\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/Federated/Pytorch/aijack/attack/inversion/gradientinversion.py?line=360'>361</a>\u001b[0m     fake_gradients, received_gradients, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgradient_ignore_pos\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/Federated/Pytorch/aijack/attack/inversion/gradientinversion.py?line=361'>362</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/Federated/Pytorch/aijack/attack/inversion/gradientinversion.py?line=362'>363</a>\u001b[0m distance \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_culc_regularization_term(\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/Federated/Pytorch/aijack/attack/inversion/gradientinversion.py?line=363'>364</a>\u001b[0m     fake_x,\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/Federated/Pytorch/aijack/attack/inversion/gradientinversion.py?line=364'>365</a>\u001b[0m     fake_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/Federated/Pytorch/aijack/attack/inversion/gradientinversion.py?line=367'>368</a>\u001b[0m     received_gradients,\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/Federated/Pytorch/aijack/attack/inversion/gradientinversion.py?line=368'>369</a>\u001b[0m )\n\u001b[1;32m--> <a href='file:///d%3A/Projects/TRUSTCOM2022/Federated/Pytorch/aijack/attack/inversion/gradientinversion.py?line=370'>371</a>\u001b[0m distance\u001b[39m.\u001b[39;49mbackward(retain_graph\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/Federated/Pytorch/aijack/attack/inversion/gradientinversion.py?line=371'>372</a>\u001b[0m \u001b[39mreturn\u001b[39;00m distance\n",
      "File \u001b[1;32md:\\Projects\\TRUSTCOM2022\\.venv\\lib\\site-packages\\torch\\_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/_tensor.py?line=353'>354</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/_tensor.py?line=354'>355</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/_tensor.py?line=355'>356</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/_tensor.py?line=356'>357</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/_tensor.py?line=360'>361</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/_tensor.py?line=361'>362</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/_tensor.py?line=362'>363</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32md:\\Projects\\TRUSTCOM2022\\.venv\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/autograd/__init__.py?line=167'>168</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/autograd/__init__.py?line=169'>170</a>\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/autograd/__init__.py?line=170'>171</a>\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/autograd/__init__.py?line=171'>172</a>\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/autograd/__init__.py?line=172'>173</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/autograd/__init__.py?line=173'>174</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/autograd/__init__.py?line=174'>175</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 4.00 GiB total capacity; 3.46 GiB already allocated; 0 bytes free; 3.49 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "###### List containing info about learning #########\n",
    "losses_train = []\n",
    "losses_test = []\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "# Runnining FL\n",
    "\n",
    "victim_count = 0 \n",
    "for r in range(num_rounds):\n",
    "    # select random clients\n",
    "    client_idx = np.random.permutation(num_clients)[:num_selected]\n",
    "    # client update\n",
    "    loss = 0\n",
    "    \n",
    "    for i in tqdm(range(num_selected)):\n",
    "        client_loss, received_gradients = client_update(client_models[i], opt[i], train_loader[client_idx[i]], epoch=1)\n",
    "        loss += client_loss.item()\n",
    "        \n",
    "    losses_train.append(loss)\n",
    "    # server aggregate\n",
    "    server_aggregate(global_model, client_models)\n",
    "    \n",
    "    test_loss, acc = test(global_model, test_loader)\n",
    "    losses_test.append(test_loss)\n",
    "    acc_test.append(acc)\n",
    "    print('%d-th round' % r)\n",
    "    print('average train loss %0.3g | test loss %0.3g | test acc: %0.3f' % (loss / num_selected, test_loss, acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(global_model.fc[0].weight.shape)\n",
    "global_model.fc[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{k: (v.dtype, v.shape) for k, v in global_model.state_dict().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_weights = global_model.body.state_dict()\n",
    "# Reshape weights for Keras model\n",
    "keras_weights = [w.cpu().numpy() for w in torch_weights.values()]\n",
    "\n",
    "for i in [0, 2, 9, 16]:\n",
    "    print(keras_weights[i].shape)\n",
    "    # conv2d layer: Torch (out,in,h,w) Keras (h,w,in,out)\n",
    "    keras_weights[i] = np.moveaxis(keras_weights[i], [0,1], [-1,-2])\n",
    "\n",
    "keras_weights.append(global_model.fc[0].weight.cpu().detach().numpy().T)\n",
    "print(keras_weights[len(keras_weights)-1].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(global_model, \"../../pretrained/test_torch.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_model = torch.load(\"../../pretrained/test_torch.pt\")\n",
    "torch_weights = torch_model.body.state_dict()\n",
    "# Reshape weights for Keras model\n",
    "keras_weights = [w.cpu().numpy() for w in torch_weights.values()]\n",
    "\n",
    "for i in [0, 2, 9, 16]:\n",
    "    print(keras_weights[i].shape)\n",
    "    # conv2d layer: Torch (out,in,h,w) Keras (h,w,in,out)\n",
    "    keras_weights[i] = np.moveaxis(keras_weights[i], [0,1], [-1,-2])\n",
    "keras_weights.append(torch_model.fc[0].weight.cpu().detach().numpy().T)\n",
    "print(keras_weights[len(keras_weights)-1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_keras = [v for v in keras_weights if v.shape != ()]\n",
    "len(new_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "968934d88acb7fa4003ed11a52074e68ba95c397f9757dc45b04b92654f10ea7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
