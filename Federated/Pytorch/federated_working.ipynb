{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data.dataset import Dataset \n",
    "from aijack.attack import GradientInversion_Attack\n",
    "from matplotlib import pyplot as plt  \n",
    "torch.backends.cudnn.benchmark=True\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clients = 10\n",
    "num_selected = 10\n",
    "num_rounds = 5\n",
    "epochs = 5\n",
    "batch_size = 3\n",
    "client_victim = 1\n",
    "data = \"CIFAR10\"\n",
    "chosen_model = ''\n",
    "if data == \"CIFAR10\":\n",
    "    chosen_model = 'test'\n",
    "    channels = 3\n",
    "    norm = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    hideen=768\n",
    "    img_shape = (channels, 32, 32)\n",
    "else:\n",
    "    chosen_model = 'test'\n",
    "    channels = 1\n",
    "    norm = transforms.Normalize((0.5), (0.5))\n",
    "    hideen=588\n",
    "    img_shape = (channels, 28, 28)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "##### Creating desired data distribution among clients  #####\n",
    "#############################################################\n",
    "\n",
    "# Image augmentation \n",
    "transform_train = transforms.Compose([\n",
    "    # transforms.RandomCrop(32, padding=4),\n",
    "    # transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    # norm,\n",
    "])\n",
    "\n",
    "if data == \"CIFAR10\":\n",
    "    # Loading CIFAR10 using torchvision.datasets\n",
    "    traindata = datasets.CIFAR10('./data', train=True, download=True,\n",
    "                        transform= transform_train)\n",
    "else:\n",
    "    # Loading CIFAR10 using torchvision.datasets\n",
    "    traindata = datasets.MNIST('./data', train=True, download=True,\n",
    "                        transform= transform_train)\n",
    "\n",
    "# Dividing the training data into num_clients, with each client having equal number of images\n",
    "# traindata_split = torch.utils.data.random_split(traindata, [int(traindata.data.shape[0] / num_clients) for _ in range(num_clients)])\n",
    "\n",
    "traindata_split = torch.utils.data.random_split(traindata, [100 for _ in range(500)])\n",
    "traindata_split = traindata_split[:10]\n",
    "torch.save(traindata_split, '../../data/cifar10.pth')\n",
    "\n",
    "# Creating a pytorch loader for a Deep Learning model\n",
    "train_loader = [torch.utils.data.DataLoader(x, batch_size=batch_size, shuffle=True) for x in torch.load('../../data/MNIST.pth')]\n",
    "\n",
    "# Normalizing the test images\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    norm,\n",
    "])\n",
    "\n",
    "if data == \"CIFAR10\":\n",
    "    # Loading the test iamges and thus converting them into a test_loader\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "            datasets.CIFAR10('./data', train=False, transform=transform_test\n",
    "            ), batch_size=batch_size, shuffle=True)\n",
    "else:\n",
    "    # Loading the test iamges and thus converting them into a test_loader\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "            datasets.MNIST('./data', train=False, transform=transform_test\n",
    "            ), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog   car   ship \n"
     ]
    }
   ],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader[0])\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "print(images[0].shape)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "##### Neural Network model #####\n",
    "#################################\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, channels=channels, hideen=hideen, num_classes=10):\n",
    "        super(VGG, self).__init__()\n",
    "        self.body = nn.Sequential(\n",
    "            nn.Conv2d(channels, 32, kernel_size=(3,3), stride=(2,2), padding=1),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv2d(32, 64, kernel_size=(3,3), padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv2d(64, 128, kernel_size=(3,3), stride=(2,2), padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv2d(128, 256, kernel_size=(3,3), padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(12544, num_classes)\n",
    "            # nn.Linear(hideen, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.body(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def client_update(client_model, optimizer, train_loader, epoch=5):\n",
    "    \"\"\"\n",
    "    This function updates/trains client model on client data\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    for e in range(epoch):\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            \n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            output = client_model(data)\n",
    "            # loss = F.nll_loss(output, target)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward(retain_graph=True)\n",
    "            \n",
    "            received_gradients = torch.autograd.grad(loss, client_model.parameters())\n",
    "            received_gradients = [cg.detach() for cg in received_gradients]            \n",
    "                \n",
    "            optimizer.step()\n",
    "    return loss, received_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def server_aggregate(global_model, client_models):\n",
    "    \"\"\"\n",
    "    This function has aggregation method 'mean'\n",
    "    \"\"\"\n",
    "    ### This will take simple mean of the weights of models ###\n",
    "    global_dict = global_model.state_dict()\n",
    "    for k in global_dict.keys():\n",
    "        global_dict[k] = torch.stack([client_models[i].state_dict()[k].float() for i in range(len(client_models))], 0).mean(0)\n",
    "    global_model.load_state_dict(global_dict)\n",
    "    for model in client_models:\n",
    "        model.load_state_dict(global_model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(global_model, test_loader):\n",
    "    \"\"\"This function test the global model on test data and returns test loss and test accuracy \"\"\"\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            output = global_model(data)\n",
    "            # test_loss += F.nll_loss(output, target).item() # sum up batch loss\n",
    "            test_loss += criterion(output, target).item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    acc = correct / len(test_loader.dataset)\n",
    "\n",
    "    return test_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "#### Initializing models and optimizer  ####\n",
    "############################################\n",
    "\n",
    "#### global model ##########\n",
    "global_model =  VGG().cuda()\n",
    "\n",
    "############## client models ##############\n",
    "client_models = [ VGG().cuda() for _ in range(num_selected)]\n",
    "for model in client_models:\n",
    "    model.load_state_dict(global_model.state_dict()) ### initial synchronizing with global model \n",
    "\n",
    "############### optimizers ################\n",
    "opt = [optim.SGD(model.parameters(), lr=0.1) for model in client_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "###### List containing info about learning #########\n",
    "losses_train = []\n",
    "losses_test = []\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "# Runnining FL\n",
    "\n",
    "victim_count = 0 \n",
    "for r in range(num_rounds):\n",
    "    # select random clients\n",
    "    client_idx = np.random.permutation(num_clients)[:num_selected]\n",
    "    # client update\n",
    "    loss = 0\n",
    "    \n",
    "    for i in tqdm(range(num_selected)):\n",
    "        client_loss, received_gradients = client_update(client_models[i], opt[i], train_loader[client_idx[i]], epoch=1)\n",
    "        loss += client_loss.item()\n",
    "        \n",
    "    losses_train.append(loss)\n",
    "    # server aggregate\n",
    "    server_aggregate(global_model, client_models)\n",
    "    \n",
    "    test_loss, acc = test(global_model, test_loader)\n",
    "    losses_test.append(test_loss)\n",
    "    acc_test.append(acc)\n",
    "    print('%d-th round' % r)\n",
    "    print('average train loss %0.3g | test loss %0.3g | test acc: %0.3f' % (loss / num_selected, test_loss, acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(global_model.fc[0].weight.shape)\n",
    "global_model.fc[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{k: (v.dtype, v.shape) for k, v in global_model.state_dict().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_weights = global_model.body.state_dict()\n",
    "# Reshape weights for Keras model\n",
    "keras_weights = [w.cpu().numpy() for w in torch_weights.values()]\n",
    "\n",
    "for i in [0, 2, 9, 16]:\n",
    "    print(keras_weights[i].shape)\n",
    "    # conv2d layer: Torch (out,in,h,w) Keras (h,w,in,out)\n",
    "    keras_weights[i] = np.moveaxis(keras_weights[i], [0,1], [-1,-2])\n",
    "\n",
    "keras_weights.append(global_model.fc[0].weight.cpu().detach().numpy().T)\n",
    "print(keras_weights[len(keras_weights)-1].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(global_model, \"../../pretrained/test_torch.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_model = torch.load(\"../../pretrained/test_torch.pt\")\n",
    "torch_weights = torch_model.body.state_dict()\n",
    "# Reshape weights for Keras model\n",
    "keras_weights = [w.cpu().numpy() for w in torch_weights.values()]\n",
    "\n",
    "for i in [0, 2, 9, 16]:\n",
    "    print(keras_weights[i].shape)\n",
    "    # conv2d layer: Torch (out,in,h,w) Keras (h,w,in,out)\n",
    "    keras_weights[i] = np.moveaxis(keras_weights[i], [0,1], [-1,-2])\n",
    "keras_weights.append(torch_model.fc[0].weight.cpu().detach().numpy().T)\n",
    "print(keras_weights[len(keras_weights)-1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_keras = [v for v in keras_weights if v.shape != ()]\n",
    "len(new_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "968934d88acb7fa4003ed11a52074e68ba95c397f9757dc45b04b92654f10ea7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
