{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision.utils import save_image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from aijack.attack import GradientInversion_Attack\n",
    "from aijack.utils import NumpyDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self, channel=3, hideen=588, num_classes=10):\n",
    "        super(LeNet, self).__init__()\n",
    "        act = nn.Sigmoid\n",
    "        self.body = nn.Sequential(\n",
    "            nn.Conv2d(channel, 12, kernel_size=5, padding=5 // 2, stride=2),\n",
    "            nn.BatchNorm2d(12),\n",
    "            act(),\n",
    "            nn.Conv2d(12, 12, kernel_size=5, padding=5 // 2, stride=2),\n",
    "            nn.BatchNorm2d(12),\n",
    "            act(),\n",
    "            nn.Conv2d(12, 12, kernel_size=5, padding=5 // 2, stride=1),\n",
    "            nn.BatchNorm2d(12),\n",
    "            act(),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hideen, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.body(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = transforms.Compose(\n",
    "#     [transforms.ToTensor(),\n",
    "#      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# batch_size = 3\n",
    "\n",
    "# trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "#                                         download=True, transform=transform)\n",
    "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "#                                           shuffle=True, num_workers=2)\n",
    "\n",
    "# testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "#                                        download=True, transform=transform)\n",
    "# testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "#                                          shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "# dataiter = iter(trainloader)\n",
    "# images, labels = dataiter.next()\n",
    "# images, labels = images.cuda(), labels.cuda()\n",
    "\n",
    "# show images\n",
    "# imshow(torchvision.utils.make_grid(images.cpu()))\n",
    "# print labels\n",
    "# print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.load('generated_images.pth')\n",
    "labels = torch.load('generated_labels.pth')\n",
    "# print(labels[8][1])\n",
    "\n",
    "for i in range(4):\n",
    "    fig = plt.figure(figsize=(17,17))\n",
    "    for bid in range(25):\n",
    "        ax1 = fig.add_subplot(1, 25, bid+1)\n",
    "        img1= images[1][bid+25*i]\n",
    "        ax1.imshow(torchvision.utils.make_grid(img1))\n",
    "        ax1.set_title(labels[1][bid+25*i])\n",
    "        ax1.axis(\"off\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from aijack.attack import GradientInversion_Attack\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self, channel=1, hideen=588, num_classes=10):\n",
    "        super(LeNet, self).__init__()\n",
    "        act = nn.Sigmoid\n",
    "        self.body = nn.Sequential(\n",
    "            nn.Conv2d(channel, 12, kernel_size=5, padding=5 // 2, stride=2),\n",
    "            nn.BatchNorm2d(12),\n",
    "            act(),\n",
    "            nn.Conv2d(12, 12, kernel_size=5, padding=5 // 2, stride=2),\n",
    "            nn.BatchNorm2d(12),\n",
    "            act(),\n",
    "            nn.Conv2d(12, 12, kernel_size=5, padding=5 // 2, stride=1),\n",
    "            nn.BatchNorm2d(12),\n",
    "            act(),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hideen, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.body(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "batch_size = 3\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_loader = [torch.utils.data.DataLoader(x, batch_size=batch_size, shuffle=True) for x in torch.load('../data/MNIST.pth')]\n",
    "\n",
    "generated_images = []\n",
    "generated_labels = []\n",
    "\n",
    "for i in range(2):\n",
    "    client_img = []\n",
    "    client_label = []\n",
    "    dataiter = iter(train_loader[i])\n",
    "\n",
    "    # for batch_idx in range(len(train_loader[i])):\n",
    "    for batch_idx in range(3):\n",
    "        print(\"Client \"+ str(i) +\" | batch \"+str(batch_idx) + \" | total imgs \" + str(len(client_img)))\n",
    "        images, labels = dataiter.next()\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        # net = LeNet(channel=3, hideen=768, num_classes=10)\n",
    "        net = LeNet(channel=1, num_classes=10)\n",
    "        net.to(device)\n",
    "        pred = net(images[:batch_size])\n",
    "        loss = criterion(pred, labels[:batch_size])\n",
    "        received_gradients = torch.autograd.grad(loss, net.parameters())\n",
    "        received_gradients = [cg.detach() for cg in received_gradients]\n",
    "\n",
    "        gradinversion = GradientInversion_Attack(net, (1, 28, 28), num_iteration=1000,\n",
    "                                            lr=1e2, log_interval=0,\n",
    "                                            optimizer_class=torch.optim.SGD,\n",
    "                                            distancename=\"l2\", optimize_label=False,\n",
    "                                            bn_reg_layers=[net.body[1], net.body[4], net.body[7]],\n",
    "                                            group_num = 3,\n",
    "                                            tv_reg_coef=0.00, l2_reg_coef=0.0001,\n",
    "                                            bn_reg_coef=0.001, gc_reg_coef=0.001, device=device)\n",
    "\n",
    "        result = gradinversion.group_attack(received_gradients, batch_size=batch_size)\n",
    "        \n",
    "        fig = plt.figure()\n",
    "        for bid in range(batch_size):\n",
    "            test_img = torch.from_numpy(((sum(result[0]) / len(result[0])).cpu().detach().numpy()[bid]))\n",
    "            img1 = test_img.swapaxes(0,1)\n",
    "            img1 = img1.swapaxes(1,2)\n",
    "            ax1 = fig.add_subplot(2, batch_size, bid+1)\n",
    "            test_img = torch.from_numpy(((sum(result[0]) / len(result[0])).cpu().detach().numpy()[bid]))\n",
    "            img1 = test_img.swapaxes(0,1)\n",
    "            img1 = img1.swapaxes(1,2)\n",
    "            ax1.imshow(torchvision.utils.make_grid(img1))\n",
    "            ax1.set_title(result[1][0][bid].item())\n",
    "            ax1.axis(\"off\")\n",
    "            \n",
    "            client_img.append(img1)\n",
    "            label = result[1][0][bid].item()\n",
    "            client_label.append(label)\n",
    "        plt.show()\n",
    "    generated_images.append(client_img)\n",
    "    generated_labels.append(client_label)\n",
    "# torch.save(generated_images, 'generated_images2.pth')\n",
    "# torch.save(generated_labels, 'generated_labels2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_out(attacker, received_gradients, batch_size=0):\n",
    "    num_seeds=3\n",
    "    fig = plt.figure()\n",
    "    fig.set_figheight(7)\n",
    "    fig.set_figwidth(7)\n",
    "    for s in tqdm(range(num_seeds)):\n",
    "        attacker.reset_seed(s)\n",
    "        if batch_size > 0:\n",
    "            result = attacker.attack(received_gradients, batch_size=batch_size)\n",
    "        else:\n",
    "            result = attacker.attack(received_gradients)\n",
    "        ax1 = fig.add_subplot(3, num_seeds, s+1)\n",
    "        test_img = torch.from_numpy((result[0].cpu().detach().numpy()[0])) / 2 + 0.5\n",
    "        img1 = test_img.swapaxes(0,1)\n",
    "        img1 = img1.swapaxes(1,2)\n",
    "        ax1.imshow(torchvision.utils.make_grid(img1))\n",
    "        ax1.set_title(torch.argmax(result[1]).item())\n",
    "        ax1.axis(\"off\")\n",
    "        ax2 = fig.add_subplot(3, num_seeds, num_seeds+s+1)\n",
    "        ax2.imshow(result[0].cpu().detach().numpy()[0][0], cmap=\"gray\")\n",
    "        ax2.axis(\"off\")\n",
    "        ax3 = fig.add_subplot(3, num_seeds, num_seeds + num_seeds+s+1)\n",
    "        ax3.imshow(cv2.medianBlur(result[0].cpu().detach().numpy()[0][0], 5), cmap=\"gray\")\n",
    "        ax3.axis(\"off\")\n",
    "    plt.suptitle(\"Result\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DLG Attack\n",
    "https://dlg.mit.edu/assets/NeurIPS19_deep_leakage_from_gradients.pdf\n",
    "\n",
    "- distance metric = L2 norm\n",
    "- optimize both of images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(torchvision.utils.make_grid(images[0].cpu()))\n",
    "print(\"Target\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "net = LeNet(channel=3, hideen=768, num_classes=10)\n",
    "net.to(device)\n",
    "pred = net(images[:1])\n",
    "loss = criterion(pred, labels[:1])\n",
    "received_gradients = torch.autograd.grad(loss, net.parameters())\n",
    "received_gradients = [cg.detach() for cg in received_gradients]\n",
    "\n",
    "dlg_attacker = GradientInversion_Attack(net, (3, 32, 32), lr=1.0, log_interval=0,\n",
    "                                    num_iteration=1000,\n",
    "                                    distancename=\"l2\", device=device)\n",
    "\n",
    "draw_out(dlg_attacker, received_gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_out(dlg_attacker, received_gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GS Attack\n",
    "https://arxiv.org/abs/2003.14053\n",
    "- distance metric = cosine similarity\n",
    "- optimize both of images and labels\n",
    "- total-variance regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imshow(torchvision.utils.make_grid(images[0].cpu()))\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# net = LeNet(channel=3, hideen=768, num_classes=10)\n",
    "# net.to(device)\n",
    "# pred = net(images[:1])\n",
    "# loss = criterion(pred, labels[:1])\n",
    "# received_gradients = torch.autograd.grad(loss, net.parameters())\n",
    "# received_gradients = [cg.detach() for cg in received_gradients]\n",
    "\n",
    "# gs_attacker = GradientInversion_Attack(net, (3, 32, 32), lr=1.0, log_interval=0,\n",
    "#                                     num_iteration=200,\n",
    "#                                     tv_reg_coef=0.01,\n",
    "#                                     distancename=\"cossim\", device=device)\n",
    "\n",
    "# draw_out(gs_attacker, received_gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IDLG Attack\n",
    "https://arxiv.org/abs/2001.02610\n",
    "- distance metric = L2 norm\n",
    "- optimize only an image & estimate a label from the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(torchvision.utils.make_grid(images[0].cpu()))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "net = LeNet(channel=3, hideen=768, num_classes=10)\n",
    "net.to(device)\n",
    "pred = net(images[:1])\n",
    "loss = criterion(pred, labels[:1])\n",
    "received_gradients = torch.autograd.grad(loss, net.parameters())\n",
    "received_gradients = [cg.detach() for cg in received_gradients]\n",
    "\n",
    "idlg_attacker = GradientInversion_Attack(net, (3, 32, 32), lr=10e2, log_interval=0,\n",
    "                                    optimizer_class=torch.optim.SGD,\n",
    "                                    distancename=\"l2\", optimize_label=False,\n",
    "                                    num_iteration=10000, device=device)\n",
    "\n",
    "draw_out(idlg_attacker, received_gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPL Attack\n",
    "https://arxiv.org/abs/2004.10397\n",
    "- distance metric = L2 norm\n",
    "- optimize only images & estimate an label from the gradients\n",
    "- label-matching regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images[0].cpu()))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "net = LeNet(channel=3, hideen=768, num_classes=10)\n",
    "net.to(device)\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.1)\n",
    "# for epoch in range(10):\n",
    "pred = net(images[:1])\n",
    "loss = criterion(pred, labels[:1])\n",
    "loss.backward(retain_graph=True)\n",
    "received_gradients = torch.autograd.grad(loss, net.parameters())\n",
    "received_gradients = [cg.detach()for cg in received_gradients]\n",
    "\n",
    "cpl_attacker = GradientInversion_Attack(net, (3, 32, 32), lr=10e2, log_interval=0,\n",
    "                                    optimizer_class=torch.optim.SGD,\n",
    "                                    distancename=\"l2\", optimize_label=False,\n",
    "                                    num_iteration=10000,\n",
    "                                    lm_reg_coef=0.01, device=device)\n",
    "\n",
    "draw_out(cpl_attacker, received_gradients)\n",
    "\n",
    "    # optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Atk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.optim as optim\n",
    "\n",
    "# imshow(torchvision.utils.make_grid(images[0:3].cpu()))\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# net = LeNet(channel=3, hideen=768, num_classes=10)\n",
    "# net.to(device)\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.1)\n",
    "# for epoch in range(3):\n",
    "#     pred = net(images[:1])\n",
    "\n",
    "#     loss = criterion(pred, labels[:1])\n",
    "#     loss.backward(retain_graph=True)\n",
    "\n",
    "#     received_gradients = torch.autograd.grad(loss, net.parameters())\n",
    "#     received_gradients = [cg.detach()/(-0.1)  for cg in received_gradients]\n",
    "    \n",
    "#     optimizer.step()\n",
    "    \n",
    "# cpl_attacker = GradientInversion_Attack(net, (3, 32, 32), lr=10e2, log_interval=0,\n",
    "#                                     optimizer_class=torch.optim.SGD,\n",
    "#                                     distancename=\"l2\", optimize_label=False,\n",
    "#                                     num_iteration=10000,\n",
    "#                                     lm_reg_coef=0.01, device=device)\n",
    "\n",
    "# draw_out(cpl_attacker, received_gradients, batch_size=3)\n",
    "    \n",
    "# gradinversion = GradientInversion_Attack(net, (3, 32, 32), num_iteration=1900,\n",
    "#                                         lr=1e2, log_interval=0,\n",
    "#                                         optimizer_class=torch.optim.SGD,\n",
    "#                                         distancename=\"l2\", optimize_label=False,\n",
    "#                                         bn_reg_layers=[net.body[1], net.body[4], net.body[7]],\n",
    "#                                         group_num = 3,\n",
    "#                                         tv_reg_coef=0.00, l2_reg_coef=0.0001,\n",
    "#                                         bn_reg_coef=0.001, gc_reg_coef=0.001, device=device)\n",
    "\n",
    "# result = gradinversion.group_attack(received_gradients, batch_size=batch_size)\n",
    "\n",
    "# fig = plt.figure()\n",
    "# for bid in range(batch_size):\n",
    "#     ax1 = fig.add_subplot(2, batch_size, bid+1)\n",
    "#     test_img = torch.from_numpy(((sum(result[0]) / len(result[0])).cpu().detach().numpy()[bid]))\n",
    "#     img1 = test_img.swapaxes(0,1)\n",
    "#     img1 = img1.swapaxes(1,2)\n",
    "#     ax1.imshow(torchvision.utils.make_grid(img1))\n",
    "#     ax1.set_title(result[1][0][bid].item())\n",
    "#     ax1.axis(\"off\")\n",
    "#     ax2 = fig.add_subplot(2, batch_size, batch_size+bid+1)\n",
    "#     ax2.imshow((sum(result[0]) / len(result[0])).cpu().detach().numpy()[bid][0], cmap=\"gray\")\n",
    "#     ax2.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradInversion\n",
    "https://arxiv.org/abs/2104.07586\n",
    "- distance metric = L2 norm\n",
    "- optimize only images & estimate labels from the gradients\n",
    "- total-variance, l2, bn, and group-consistency regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "train_loader = [torch.utils.data.DataLoader(x, batch_size=batch_size, shuffle=True) for x in torch.load('../data/cifar10.pth')]\n",
    "for i in range(len(train_loader)):\n",
    "    dataiter = iter(train_loader[i])\n",
    "    images, labels = dataiter.next()\n",
    "    images = images.cuda()\n",
    "    labels = labels.cuda()\n",
    "\n",
    "    imshow(torchvision.utils.make_grid(images.cpu()))\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    net = LeNet(channel=3, hideen=768, num_classes=10)\n",
    "    net.to(device)\n",
    "    pred = net(images[:batch_size])\n",
    "    loss = criterion(pred, labels[:batch_size])\n",
    "    received_gradients = torch.autograd.grad(loss, net.parameters())\n",
    "    received_gradients = [cg.detach() for cg in received_gradients]\n",
    "\n",
    "    gradinversion = GradientInversion_Attack(net, (3, 32, 32), num_iteration=900,\n",
    "                                        lr=1e2, log_interval=0,\n",
    "                                        optimizer_class=torch.optim.SGD,\n",
    "                                        distancename=\"l2\", optimize_label=False,\n",
    "                                        bn_reg_layers=[net.body[1], net.body[4], net.body[7]],\n",
    "                                        group_num = 3,\n",
    "                                        tv_reg_coef=0.00, l2_reg_coef=0.0001,\n",
    "                                        bn_reg_coef=0.001, gc_reg_coef=0.001, device=device)\n",
    "\n",
    "    result = gradinversion.group_attack(received_gradients, batch_size=batch_size)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    for bid in range(batch_size):\n",
    "        ax1 = fig.add_subplot(2, batch_size, bid+1)\n",
    "        test_img = torch.from_numpy(((sum(result[0]) / len(result[0])).cpu().detach().numpy()[bid]))\n",
    "        img1 = test_img.swapaxes(0,1)\n",
    "        img1 = img1.swapaxes(1,2)\n",
    "        ax1.imshow(torchvision.utils.make_grid(img1))\n",
    "        ax1.set_title(result[1][0][bid].item())\n",
    "        ax1.axis(\"off\")\n",
    "        # ax2 = fig.add_subplot(2, batch_size, batch_size+bid+1)\n",
    "        # ax2.imshow((sum(result[0]) / len(result[0])).cpu().detach().numpy()[bid][0], cmap=\"gray\")\n",
    "        # ax2.axis(\"off\")\n",
    "\n",
    "    plt.suptitle(\"Result of GradInversion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "968934d88acb7fa4003ed11a52074e68ba95c397f9757dc45b04b92654f10ea7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
