{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision.utils import save_image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from aijack.attack import GradientInversion_Attack\n",
    "from aijack.utils import NumpyDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self, channel=3, hideen=588, num_classes=10):\n",
    "        super(LeNet, self).__init__()\n",
    "        act = nn.Sigmoid\n",
    "        self.body = nn.Sequential(\n",
    "            nn.Conv2d(channel, 12, kernel_size=5, padding=5 // 2, stride=2),\n",
    "            nn.BatchNorm2d(12),\n",
    "            act(),\n",
    "            nn.Conv2d(12, 12, kernel_size=5, padding=5 // 2, stride=2),\n",
    "            nn.BatchNorm2d(12),\n",
    "            act(),\n",
    "            nn.Conv2d(12, 12, kernel_size=5, padding=5 // 2, stride=1),\n",
    "            nn.BatchNorm2d(12),\n",
    "            act(),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hideen, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.body(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.load('generated_images1.pth')\n",
    "labels = torch.load('generated_labels1.pth')\n",
    "# print(labels[8][1])\n",
    "\n",
    "for i in range(4):\n",
    "    fig = plt.figure(figsize=(17,17))\n",
    "    for bid in range(25):\n",
    "        ax1 = fig.add_subplot(1, 25, bid+1)\n",
    "        img1= images[1][bid+25*i]\n",
    "        ax1.imshow(torchvision.utils.make_grid(img1))\n",
    "        ax1.set_title(labels[1][bid+25*i])\n",
    "        ax1.axis(\"off\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0 | batch 0 | total imgs 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0 | batch 1 | total imgs 3\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 4.00 GiB total capacity; 3.45 GiB already allocated; 0 bytes free; 3.49 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\Projects\\TRUSTCOM2022\\GradientInversion\\gradientInversion.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 46>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/TRUSTCOM2022/GradientInversion/gradientInversion.ipynb#ch0000006?line=64'>65</a>\u001b[0m received_gradients \u001b[39m=\u001b[39m [cg\u001b[39m.\u001b[39mdetach() \u001b[39mfor\u001b[39;00m cg \u001b[39min\u001b[39;00m received_gradients]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/TRUSTCOM2022/GradientInversion/gradientInversion.ipynb#ch0000006?line=66'>67</a>\u001b[0m gradinversion \u001b[39m=\u001b[39m GradientInversion_Attack(net, (\u001b[39m1\u001b[39m, \u001b[39m28\u001b[39m, \u001b[39m28\u001b[39m), num_iteration\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/TRUSTCOM2022/GradientInversion/gradientInversion.ipynb#ch0000006?line=67'>68</a>\u001b[0m                                     lr\u001b[39m=\u001b[39m\u001b[39m1e2\u001b[39m, log_interval\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/TRUSTCOM2022/GradientInversion/gradientInversion.ipynb#ch0000006?line=68'>69</a>\u001b[0m                                     optimizer_class\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mSGD,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/TRUSTCOM2022/GradientInversion/gradientInversion.ipynb#ch0000006?line=72'>73</a>\u001b[0m                                     tv_reg_coef\u001b[39m=\u001b[39m\u001b[39m0.00\u001b[39m, l2_reg_coef\u001b[39m=\u001b[39m\u001b[39m0.0001\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/TRUSTCOM2022/GradientInversion/gradientInversion.ipynb#ch0000006?line=73'>74</a>\u001b[0m                                     bn_reg_coef\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m, gc_reg_coef\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m, device\u001b[39m=\u001b[39mdevice)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Projects/TRUSTCOM2022/GradientInversion/gradientInversion.ipynb#ch0000006?line=75'>76</a>\u001b[0m result \u001b[39m=\u001b[39m gradinversion\u001b[39m.\u001b[39;49mgroup_attack(received_gradients, batch_size\u001b[39m=\u001b[39;49mbatch_size)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/TRUSTCOM2022/GradientInversion/gradientInversion.ipynb#ch0000006?line=77'>78</a>\u001b[0m fig \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mfigure()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/TRUSTCOM2022/GradientInversion/gradientInversion.ipynb#ch0000006?line=78'>79</a>\u001b[0m \u001b[39mfor\u001b[39;00m bid \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(batch_size):\n",
      "File \u001b[1;32md:\\Projects\\TRUSTCOM2022\\GradientInversion\\aijack\\attack\\inversion\\gradientinversion.py:529\u001b[0m, in \u001b[0;36mGradientInversion_Attack.group_attack\u001b[1;34m(self, received_gradients, batch_size)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/GradientInversion/aijack/attack/inversion/gradientinversion.py?line=521'>522</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset_seed(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroup_seed[worker_id])\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/GradientInversion/aijack/attack/inversion/gradientinversion.py?line=522'>523</a>\u001b[0m closure \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setup_closure(\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/GradientInversion/aijack/attack/inversion/gradientinversion.py?line=523'>524</a>\u001b[0m     group_optimizer[worker_id],\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/GradientInversion/aijack/attack/inversion/gradientinversion.py?line=524'>525</a>\u001b[0m     group_fake_x[worker_id],\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/GradientInversion/aijack/attack/inversion/gradientinversion.py?line=525'>526</a>\u001b[0m     group_fake_label[worker_id],\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/GradientInversion/aijack/attack/inversion/gradientinversion.py?line=526'>527</a>\u001b[0m     received_gradients,\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/GradientInversion/aijack/attack/inversion/gradientinversion.py?line=527'>528</a>\u001b[0m )\n\u001b[1;32m--> <a href='file:///d%3A/Projects/TRUSTCOM2022/GradientInversion/aijack/attack/inversion/gradientinversion.py?line=528'>529</a>\u001b[0m distance \u001b[39m=\u001b[39m group_optimizer[worker_id]\u001b[39m.\u001b[39;49mstep(closure)\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/GradientInversion/aijack/attack/inversion/gradientinversion.py?line=530'>531</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_loss:\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/GradientInversion/aijack/attack/inversion/gradientinversion.py?line=531'>532</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_loss[worker_id]\u001b[39m.\u001b[39mappend(distance)\n",
      "File \u001b[1;32md:\\Projects\\TRUSTCOM2022\\.venv\\lib\\site-packages\\torch\\optim\\optimizer.py:88\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/optim/optimizer.py?line=85'>86</a>\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[0;32m     <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/optim/optimizer.py?line=86'>87</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m---> <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/optim/optimizer.py?line=87'>88</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\Projects\\TRUSTCOM2022\\.venv\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/autograd/grad_mode.py?line=23'>24</a>\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m     <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/autograd/grad_mode.py?line=24'>25</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/autograd/grad_mode.py?line=25'>26</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[1;32m---> <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/autograd/grad_mode.py?line=26'>27</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\Projects\\TRUSTCOM2022\\.venv\\lib\\site-packages\\torch\\optim\\sgd.py:120\u001b[0m, in \u001b[0;36mSGD.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/optim/sgd.py?line=117'>118</a>\u001b[0m \u001b[39mif\u001b[39;00m closure \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/optim/sgd.py?line=118'>119</a>\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39menable_grad():\n\u001b[1;32m--> <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/optim/sgd.py?line=119'>120</a>\u001b[0m         loss \u001b[39m=\u001b[39m closure()\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/optim/sgd.py?line=121'>122</a>\u001b[0m \u001b[39mfor\u001b[39;00m group \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_groups:\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/optim/sgd.py?line=122'>123</a>\u001b[0m     params_with_grad \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32md:\\Projects\\TRUSTCOM2022\\GradientInversion\\aijack\\attack\\inversion\\gradientinversion.py:372\u001b[0m, in \u001b[0;36mGradientInversion_Attack._setup_closure.<locals>.closure\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/GradientInversion/aijack/attack/inversion/gradientinversion.py?line=360'>361</a>\u001b[0m distance \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistancefunc(\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/GradientInversion/aijack/attack/inversion/gradientinversion.py?line=361'>362</a>\u001b[0m     fake_gradients, received_gradients, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgradient_ignore_pos\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/GradientInversion/aijack/attack/inversion/gradientinversion.py?line=362'>363</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/GradientInversion/aijack/attack/inversion/gradientinversion.py?line=363'>364</a>\u001b[0m distance \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_culc_regularization_term(\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/GradientInversion/aijack/attack/inversion/gradientinversion.py?line=364'>365</a>\u001b[0m     fake_x,\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/GradientInversion/aijack/attack/inversion/gradientinversion.py?line=365'>366</a>\u001b[0m     fake_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/GradientInversion/aijack/attack/inversion/gradientinversion.py?line=368'>369</a>\u001b[0m     received_gradients,\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/GradientInversion/aijack/attack/inversion/gradientinversion.py?line=369'>370</a>\u001b[0m )\n\u001b[1;32m--> <a href='file:///d%3A/Projects/TRUSTCOM2022/GradientInversion/aijack/attack/inversion/gradientinversion.py?line=371'>372</a>\u001b[0m distance\u001b[39m.\u001b[39;49mbackward(retain_graph\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/GradientInversion/aijack/attack/inversion/gradientinversion.py?line=372'>373</a>\u001b[0m \u001b[39mreturn\u001b[39;00m distance\n",
      "File \u001b[1;32md:\\Projects\\TRUSTCOM2022\\.venv\\lib\\site-packages\\torch\\_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/_tensor.py?line=353'>354</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/_tensor.py?line=354'>355</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/_tensor.py?line=355'>356</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/_tensor.py?line=356'>357</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/_tensor.py?line=360'>361</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/_tensor.py?line=361'>362</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/_tensor.py?line=362'>363</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32md:\\Projects\\TRUSTCOM2022\\.venv\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/autograd/__init__.py?line=167'>168</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/autograd/__init__.py?line=169'>170</a>\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/autograd/__init__.py?line=170'>171</a>\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/autograd/__init__.py?line=171'>172</a>\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/autograd/__init__.py?line=172'>173</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/autograd/__init__.py?line=173'>174</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    <a href='file:///d%3A/Projects/TRUSTCOM2022/.venv/lib/site-packages/torch/autograd/__init__.py?line=174'>175</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 4.00 GiB total capacity; 3.45 GiB already allocated; 0 bytes free; 3.49 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from aijack.attack import GradientInversion_Attack\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self, channel=1, hideen=588, num_classes=10):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.body = nn.Sequential(\n",
    "            nn.Conv2d(channel, 32, kernel_size=(3,3), stride=(2,2), padding=1),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv2d(32, 64, kernel_size=(3,3), padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv2d(64, 128, kernel_size=(3,3), stride=(2,2), padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(6272, num_classes)\n",
    "            # nn.Linear(hideen, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.body(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "batch_size = 3\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_loader = [torch.utils.data.DataLoader(x, batch_size=batch_size, shuffle=True) for x in torch.load('../data/MNIST.pth')]\n",
    "\n",
    "generated_images = []\n",
    "generated_labels = []\n",
    "\n",
    "for i in range(2):\n",
    "    client_img = []\n",
    "    client_label = []\n",
    "    dataiter = iter(train_loader[i])\n",
    "\n",
    "    # for batch_idx in range(len(train_loader[i])):\n",
    "    for batch_idx in range(3):\n",
    "        print(\"Client \"+ str(i) +\" | batch \"+str(batch_idx) + \" | total imgs \" + str(len(client_img)))\n",
    "        images, labels = dataiter.next()\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        # net = LeNet(channel=3, hideen=768, num_classes=10)\n",
    "        net = LeNet(channel=1, num_classes=10)\n",
    "        net.to(device)\n",
    "        pred = net(images[:batch_size])\n",
    "        loss = criterion(pred, labels[:batch_size])\n",
    "        received_gradients = torch.autograd.grad(loss, net.parameters())\n",
    "        received_gradients = [cg.detach() for cg in received_gradients]\n",
    "\n",
    "        gradinversion = GradientInversion_Attack(net, (1, 28, 28), num_iteration=500,\n",
    "                                            lr=1e2, log_interval=0,\n",
    "                                            optimizer_class=torch.optim.SGD,\n",
    "                                            distancename=\"l2\", optimize_label=False,\n",
    "                                            bn_reg_layers=[net.body[4], net.body[8]],\n",
    "                                            group_num = 3,\n",
    "                                            tv_reg_coef=0.00, l2_reg_coef=0.0001,\n",
    "                                            bn_reg_coef=0.001, gc_reg_coef=0.001, device=device)\n",
    "\n",
    "        result = gradinversion.group_attack(received_gradients, batch_size=batch_size)\n",
    "        \n",
    "        fig = plt.figure()\n",
    "        for bid in range(batch_size):\n",
    "            test_img = torch.from_numpy(((sum(result[0]) / len(result[0])).cpu().detach().numpy()[bid]))\n",
    "            img1 = test_img.swapaxes(0,1)\n",
    "            img1 = img1.swapaxes(1,2)\n",
    "            ax1 = fig.add_subplot(2, batch_size, bid+1)\n",
    "            test_img = torch.from_numpy(((sum(result[0]) / len(result[0])).cpu().detach().numpy()[bid]))\n",
    "            img1 = test_img.swapaxes(0,1)\n",
    "            img1 = img1.swapaxes(1,2)\n",
    "            ax1.imshow(torchvision.utils.make_grid(img1))\n",
    "            ax1.set_title(result[1][0][bid].item())\n",
    "            ax1.axis(\"off\")\n",
    "            \n",
    "            client_img.append(img1)\n",
    "            label = result[1][0][bid].item()\n",
    "            client_label.append(label)\n",
    "        plt.show()\n",
    "    generated_images.append(client_img)\n",
    "    generated_labels.append(client_label)\n",
    "torch.save(generated_images, 'generated_images2.pth')\n",
    "torch.save(generated_labels, 'generated_labels2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_out(attacker, received_gradients, batch_size=0):\n",
    "    num_seeds=3\n",
    "    fig = plt.figure()\n",
    "    fig.set_figheight(7)\n",
    "    fig.set_figwidth(7)\n",
    "    for s in tqdm(range(num_seeds)):\n",
    "        attacker.reset_seed(s)\n",
    "        if batch_size > 0:\n",
    "            result = attacker.attack(received_gradients, batch_size=batch_size)\n",
    "        else:\n",
    "            result = attacker.attack(received_gradients)\n",
    "        ax1 = fig.add_subplot(3, num_seeds, s+1)\n",
    "        test_img = torch.from_numpy((result[0].cpu().detach().numpy()[0])) / 2 + 0.5\n",
    "        img1 = test_img.swapaxes(0,1)\n",
    "        img1 = img1.swapaxes(1,2)\n",
    "        ax1.imshow(torchvision.utils.make_grid(img1))\n",
    "        ax1.set_title(torch.argmax(result[1]).item())\n",
    "        ax1.axis(\"off\")\n",
    "        ax2 = fig.add_subplot(3, num_seeds, num_seeds+s+1)\n",
    "        ax2.imshow(result[0].cpu().detach().numpy()[0][0], cmap=\"gray\")\n",
    "        ax2.axis(\"off\")\n",
    "        ax3 = fig.add_subplot(3, num_seeds, num_seeds + num_seeds+s+1)\n",
    "        ax3.imshow(cv2.medianBlur(result[0].cpu().detach().numpy()[0][0], 5), cmap=\"gray\")\n",
    "        ax3.axis(\"off\")\n",
    "    plt.suptitle(\"Result\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DLG Attack\n",
    "https://dlg.mit.edu/assets/NeurIPS19_deep_leakage_from_gradients.pdf\n",
    "\n",
    "- distance metric = L2 norm\n",
    "- optimize both of images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(torchvision.utils.make_grid(images[0].cpu()))\n",
    "print(\"Target\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "net = LeNet(channel=3, hideen=768, num_classes=10)\n",
    "net.to(device)\n",
    "pred = net(images[:1])\n",
    "loss = criterion(pred, labels[:1])\n",
    "received_gradients = torch.autograd.grad(loss, net.parameters())\n",
    "received_gradients = [cg.detach() for cg in received_gradients]\n",
    "\n",
    "dlg_attacker = GradientInversion_Attack(net, (3, 32, 32), lr=1.0, log_interval=0,\n",
    "                                    num_iteration=1000,\n",
    "                                    distancename=\"l2\", device=device)\n",
    "\n",
    "draw_out(dlg_attacker, received_gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_out(dlg_attacker, received_gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GS Attack\n",
    "https://arxiv.org/abs/2003.14053\n",
    "- distance metric = cosine similarity\n",
    "- optimize both of images and labels\n",
    "- total-variance regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imshow(torchvision.utils.make_grid(images[0].cpu()))\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# net = LeNet(channel=3, hideen=768, num_classes=10)\n",
    "# net.to(device)\n",
    "# pred = net(images[:1])\n",
    "# loss = criterion(pred, labels[:1])\n",
    "# received_gradients = torch.autograd.grad(loss, net.parameters())\n",
    "# received_gradients = [cg.detach() for cg in received_gradients]\n",
    "\n",
    "# gs_attacker = GradientInversion_Attack(net, (3, 32, 32), lr=1.0, log_interval=0,\n",
    "#                                     num_iteration=200,\n",
    "#                                     tv_reg_coef=0.01,\n",
    "#                                     distancename=\"cossim\", device=device)\n",
    "\n",
    "# draw_out(gs_attacker, received_gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IDLG Attack\n",
    "https://arxiv.org/abs/2001.02610\n",
    "- distance metric = L2 norm\n",
    "- optimize only an image & estimate a label from the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(torchvision.utils.make_grid(images[0].cpu()))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "net = LeNet(channel=3, hideen=768, num_classes=10)\n",
    "net.to(device)\n",
    "pred = net(images[:1])\n",
    "loss = criterion(pred, labels[:1])\n",
    "received_gradients = torch.autograd.grad(loss, net.parameters())\n",
    "received_gradients = [cg.detach() for cg in received_gradients]\n",
    "\n",
    "idlg_attacker = GradientInversion_Attack(net, (3, 32, 32), lr=10e2, log_interval=0,\n",
    "                                    optimizer_class=torch.optim.SGD,\n",
    "                                    distancename=\"l2\", optimize_label=False,\n",
    "                                    num_iteration=10000, device=device)\n",
    "\n",
    "draw_out(idlg_attacker, received_gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPL Attack\n",
    "https://arxiv.org/abs/2004.10397\n",
    "- distance metric = L2 norm\n",
    "- optimize only images & estimate an label from the gradients\n",
    "- label-matching regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images[0].cpu()))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "net = LeNet(channel=3, hideen=768, num_classes=10)\n",
    "net.to(device)\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.1)\n",
    "# for epoch in range(10):\n",
    "pred = net(images[:1])\n",
    "loss = criterion(pred, labels[:1])\n",
    "loss.backward(retain_graph=True)\n",
    "received_gradients = torch.autograd.grad(loss, net.parameters())\n",
    "received_gradients = [cg.detach()for cg in received_gradients]\n",
    "\n",
    "cpl_attacker = GradientInversion_Attack(net, (3, 32, 32), lr=10e2, log_interval=0,\n",
    "                                    optimizer_class=torch.optim.SGD,\n",
    "                                    distancename=\"l2\", optimize_label=False,\n",
    "                                    num_iteration=10000,\n",
    "                                    lm_reg_coef=0.01, device=device)\n",
    "\n",
    "draw_out(cpl_attacker, received_gradients)\n",
    "\n",
    "    # optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Atk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.optim as optim\n",
    "\n",
    "# imshow(torchvision.utils.make_grid(images[0:3].cpu()))\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# net = LeNet(channel=3, hideen=768, num_classes=10)\n",
    "# net.to(device)\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.1)\n",
    "# for epoch in range(3):\n",
    "#     pred = net(images[:1])\n",
    "\n",
    "#     loss = criterion(pred, labels[:1])\n",
    "#     loss.backward(retain_graph=True)\n",
    "\n",
    "#     received_gradients = torch.autograd.grad(loss, net.parameters())\n",
    "#     received_gradients = [cg.detach()/(-0.1)  for cg in received_gradients]\n",
    "    \n",
    "#     optimizer.step()\n",
    "    \n",
    "# cpl_attacker = GradientInversion_Attack(net, (3, 32, 32), lr=10e2, log_interval=0,\n",
    "#                                     optimizer_class=torch.optim.SGD,\n",
    "#                                     distancename=\"l2\", optimize_label=False,\n",
    "#                                     num_iteration=10000,\n",
    "#                                     lm_reg_coef=0.01, device=device)\n",
    "\n",
    "# draw_out(cpl_attacker, received_gradients, batch_size=3)\n",
    "    \n",
    "# gradinversion = GradientInversion_Attack(net, (3, 32, 32), num_iteration=1900,\n",
    "#                                         lr=1e2, log_interval=0,\n",
    "#                                         optimizer_class=torch.optim.SGD,\n",
    "#                                         distancename=\"l2\", optimize_label=False,\n",
    "#                                         bn_reg_layers=[net.body[1], net.body[4], net.body[7]],\n",
    "#                                         group_num = 3,\n",
    "#                                         tv_reg_coef=0.00, l2_reg_coef=0.0001,\n",
    "#                                         bn_reg_coef=0.001, gc_reg_coef=0.001, device=device)\n",
    "\n",
    "# result = gradinversion.group_attack(received_gradients, batch_size=batch_size)\n",
    "\n",
    "# fig = plt.figure()\n",
    "# for bid in range(batch_size):\n",
    "#     ax1 = fig.add_subplot(2, batch_size, bid+1)\n",
    "#     test_img = torch.from_numpy(((sum(result[0]) / len(result[0])).cpu().detach().numpy()[bid]))\n",
    "#     img1 = test_img.swapaxes(0,1)\n",
    "#     img1 = img1.swapaxes(1,2)\n",
    "#     ax1.imshow(torchvision.utils.make_grid(img1))\n",
    "#     ax1.set_title(result[1][0][bid].item())\n",
    "#     ax1.axis(\"off\")\n",
    "#     ax2 = fig.add_subplot(2, batch_size, batch_size+bid+1)\n",
    "#     ax2.imshow((sum(result[0]) / len(result[0])).cpu().detach().numpy()[bid][0], cmap=\"gray\")\n",
    "#     ax2.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradInversion\n",
    "https://arxiv.org/abs/2104.07586\n",
    "- distance metric = L2 norm\n",
    "- optimize only images & estimate labels from the gradients\n",
    "- total-variance, l2, bn, and group-consistency regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "train_loader = [torch.utils.data.DataLoader(x, batch_size=batch_size, shuffle=True) for x in torch.load('../data/cifar10.pth')]\n",
    "for i in range(len(train_loader)):\n",
    "    dataiter = iter(train_loader[i])\n",
    "    images, labels = dataiter.next()\n",
    "    images = images.cuda()\n",
    "    labels = labels.cuda()\n",
    "\n",
    "    imshow(torchvision.utils.make_grid(images.cpu()))\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    net = LeNet(channel=3, hideen=768, num_classes=10)\n",
    "    net.to(device)\n",
    "    pred = net(images[:batch_size])\n",
    "    loss = criterion(pred, labels[:batch_size])\n",
    "    received_gradients = torch.autograd.grad(loss, net.parameters())\n",
    "    received_gradients = [cg.detach() for cg in received_gradients]\n",
    "\n",
    "    gradinversion = GradientInversion_Attack(net, (3, 32, 32), num_iteration=900,\n",
    "                                        lr=1e2, log_interval=0,\n",
    "                                        optimizer_class=torch.optim.SGD,\n",
    "                                        distancename=\"l2\", optimize_label=False,\n",
    "                                        bn_reg_layers=[net.body[1], net.body[4], net.body[7]],\n",
    "                                        group_num = 3,\n",
    "                                        tv_reg_coef=0.00, l2_reg_coef=0.0001,\n",
    "                                        bn_reg_coef=0.001, gc_reg_coef=0.001, device=device)\n",
    "\n",
    "    result = gradinversion.group_attack(received_gradients, batch_size=batch_size)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    for bid in range(batch_size):\n",
    "        ax1 = fig.add_subplot(2, batch_size, bid+1)\n",
    "        test_img = torch.from_numpy(((sum(result[0]) / len(result[0])).cpu().detach().numpy()[bid]))\n",
    "        img1 = test_img.swapaxes(0,1)\n",
    "        img1 = img1.swapaxes(1,2)\n",
    "        ax1.imshow(torchvision.utils.make_grid(img1))\n",
    "        ax1.set_title(result[1][0][bid].item())\n",
    "        ax1.axis(\"off\")\n",
    "        # ax2 = fig.add_subplot(2, batch_size, batch_size+bid+1)\n",
    "        # ax2.imshow((sum(result[0]) / len(result[0])).cpu().detach().numpy()[bid][0], cmap=\"gray\")\n",
    "        # ax2.axis(\"off\")\n",
    "\n",
    "    plt.suptitle(\"Result of GradInversion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "968934d88acb7fa4003ed11a52074e68ba95c397f9757dc45b04b92654f10ea7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
