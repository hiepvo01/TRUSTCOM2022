{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of fitting an auxiliary classifier gan (ac-gan) on fashion mnsit\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy import expand_dims\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "\n",
    "from tensorflow.keras.datasets.fashion_mnist import load_data\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from matplotlib import pyplot\n",
    "import os\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_real_samples():\n",
    "\t# load dataset\n",
    "\ttrain_x = []\n",
    "\ttrain_y = []\n",
    "\tfor client in range(10):\n",
    "\t\tfor item in torch.load('../data/MNIST.pth')[client]:\n",
    "\t\t\timg = item[0]\n",
    "\t\t\timg = item[0].swapaxes(0,1)\n",
    "\t\t\timg = img.swapaxes(1,2)\n",
    "   \n",
    "\t\t\ttrain_x.append(np.array(img))\n",
    "\t\t\ttrain_y.append(np.array(item[1]))\n",
    "\n",
    "\t# (trainX, trainy), (_, _) = load_data()\n",
    "\t# expand to 3d, e.g. add channels\n",
    "\tX = expand_dims(train_x, axis=-1)\n",
    "\t# convert from ints to floats\n",
    "\tX = X.astype('float32')\n",
    "\t# scale from [0,255] to [-1,1]\n",
    "\tX = (X - 127.5) / 127.5\n",
    "\t# print(train_y[0])\n",
    "\treturn [np.array(X), np.array(train_y)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\TRUSTCOM2022\\.venv\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 181ms/step\n",
      ">1, dr[0.684,3.577], df[1.031,3.202], g[0.863,3.395]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      ">2, dr[0.312,2.934], df[1.023,2.472], g[0.887,3.276]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      ">3, dr[0.665,2.978], df[0.790,3.232], g[1.238,3.433]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      ">4, dr[0.759,3.239], df[0.891,2.730], g[1.157,3.377]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      ">5, dr[0.855,3.067], df[0.822,3.371], g[1.324,3.338]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      ">6, dr[0.906,2.538], df[0.695,2.978], g[1.015,3.693]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      ">7, dr[0.510,2.967], df[0.765,3.337], g[0.876,2.449]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      ">8, dr[0.753,3.019], df[1.712,2.785], g[1.432,3.097]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      ">9, dr[0.594,3.355], df[0.856,3.315], g[1.377,3.533]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      ">10, dr[0.794,3.347], df[0.424,3.258], g[1.337,3.048]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">11, dr[0.624,3.588], df[0.768,3.014], g[1.535,3.449]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      ">12, dr[0.921,3.005], df[0.474,3.008], g[1.184,3.039]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      ">13, dr[0.695,3.052], df[0.854,3.023], g[1.278,2.952]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      ">14, dr[0.405,3.343], df[0.545,2.531], g[1.848,3.265]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      ">15, dr[1.073,2.807], df[0.557,2.831], g[1.120,3.401]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      ">16, dr[0.720,3.093], df[0.828,3.741], g[0.974,3.515]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      ">17, dr[0.782,2.640], df[0.624,3.732], g[1.114,2.777]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">18, dr[0.421,4.025], df[0.432,2.843], g[1.482,3.309]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      ">19, dr[0.707,2.805], df[0.747,3.058], g[1.169,2.982]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      ">20, dr[0.460,2.992], df[0.539,3.465], g[1.457,3.619]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">21, dr[0.524,2.818], df[0.696,3.686], g[1.448,3.333]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      ">22, dr[0.422,2.297], df[0.783,3.033], g[1.352,3.232]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      ">23, dr[0.634,2.790], df[1.056,3.041], g[1.458,3.638]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      ">24, dr[0.563,3.381], df[0.338,2.816], g[1.477,2.485]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">25, dr[0.650,3.440], df[0.529,2.288], g[1.503,3.056]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">26, dr[0.477,2.593], df[0.699,4.035], g[1.474,2.904]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      ">27, dr[0.546,3.351], df[0.614,2.862], g[1.254,3.521]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      ">28, dr[0.588,2.797], df[1.174,2.587], g[0.832,3.141]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">29, dr[0.706,3.557], df[0.861,3.029], g[1.258,3.272]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">30, dr[0.718,3.170], df[0.467,3.255], g[1.396,2.625]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      ">31, dr[0.822,2.650], df[0.733,2.955], g[0.805,2.764]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      ">32, dr[0.429,3.457], df[1.003,3.721], g[1.089,3.072]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">33, dr[0.618,3.572], df[0.466,3.389], g[1.300,2.677]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      ">34, dr[0.906,3.343], df[0.836,3.497], g[1.784,3.005]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">35, dr[0.661,2.841], df[0.376,3.175], g[1.266,3.264]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      ">36, dr[1.094,2.956], df[1.085,3.663], g[0.918,3.309]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      ">37, dr[0.760,3.267], df[0.539,3.399], g[1.138,3.636]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      ">38, dr[0.327,3.448], df[0.657,3.392], g[1.242,3.287]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      ">39, dr[0.606,3.233], df[0.528,2.862], g[1.222,3.077]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      ">40, dr[0.709,3.326], df[0.669,2.696], g[0.984,2.656]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      ">41, dr[0.554,3.638], df[0.698,3.000], g[1.168,2.987]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      ">42, dr[0.498,2.666], df[0.478,2.752], g[1.115,3.492]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      ">43, dr[0.461,3.328], df[0.624,2.821], g[0.808,3.183]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      ">44, dr[0.680,2.943], df[0.455,3.036], g[0.700,3.525]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      ">45, dr[0.531,3.423], df[0.559,3.238], g[0.723,2.731]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      ">46, dr[0.895,3.564], df[1.604,3.342], g[0.854,2.530]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      ">47, dr[0.801,3.223], df[0.581,2.769], g[0.648,3.381]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      ">48, dr[0.540,3.116], df[1.058,3.029], g[0.905,2.963]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      ">49, dr[0.875,4.076], df[0.671,3.817], g[0.736,3.210]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">50, dr[0.652,3.347], df[0.594,3.027], g[0.781,3.662]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      ">51, dr[0.416,3.118], df[0.561,2.752], g[0.800,2.903]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      ">52, dr[0.658,4.289], df[0.559,2.679], g[0.823,3.265]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      ">53, dr[0.529,2.642], df[0.716,3.773], g[0.781,3.316]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      ">54, dr[1.053,3.284], df[0.665,2.630], g[0.580,3.241]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      ">55, dr[0.612,3.013], df[0.840,2.671], g[0.825,3.256]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      ">56, dr[0.352,3.239], df[0.567,2.674], g[0.877,3.107]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      ">57, dr[0.561,3.606], df[0.548,3.011], g[0.635,3.047]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      ">58, dr[0.549,2.739], df[0.404,3.375], g[0.577,2.845]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      ">59, dr[0.420,3.936], df[0.610,2.530], g[0.520,3.045]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      ">60, dr[0.860,3.611], df[0.518,3.669], g[0.571,3.154]\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      ">61, dr[0.636,3.100], df[0.822,3.013], g[0.662,2.692]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      ">62, dr[0.344,3.642], df[0.650,3.203], g[0.631,3.336]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      ">63, dr[0.407,3.435], df[0.363,3.289], g[0.515,3.426]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      ">64, dr[0.526,3.622], df[0.861,3.948], g[0.644,2.856]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      ">65, dr[0.321,2.796], df[0.410,2.967], g[0.646,2.851]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      ">66, dr[0.463,3.154], df[0.382,2.712], g[0.774,2.793]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      ">67, dr[0.422,2.474], df[0.239,2.879], g[0.391,3.001]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      ">68, dr[0.209,3.535], df[0.318,3.092], g[0.767,2.872]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      ">69, dr[0.552,2.819], df[0.386,3.407], g[0.337,2.886]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      ">70, dr[0.258,4.198], df[0.185,2.380], g[0.413,3.258]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      ">71, dr[0.144,3.656], df[0.267,3.005], g[0.493,3.155]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">72, dr[0.209,2.182], df[0.140,2.866], g[0.657,3.429]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      ">73, dr[0.375,2.534], df[0.248,3.110], g[0.293,2.720]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      ">74, dr[0.604,2.725], df[0.418,2.848], g[0.372,2.418]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      ">75, dr[0.220,2.555], df[0.407,3.588], g[0.376,3.195]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">76, dr[0.414,4.044], df[0.429,3.763], g[0.538,3.087]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">77, dr[0.114,3.454], df[0.142,3.071], g[0.405,3.483]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">78, dr[0.227,3.571], df[0.414,2.731], g[0.430,3.615]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">79, dr[0.105,3.320], df[0.271,3.613], g[0.292,3.329]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      ">80, dr[0.195,2.983], df[0.170,3.533], g[0.346,3.079]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">81, dr[0.127,3.392], df[0.254,3.052], g[0.283,3.378]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">82, dr[0.178,3.159], df[0.410,3.880], g[0.308,2.732]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">83, dr[0.280,3.093], df[0.725,3.058], g[0.647,3.154]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">84, dr[0.639,2.878], df[0.513,2.941], g[0.670,2.928]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">85, dr[0.576,3.032], df[0.304,3.529], g[0.511,2.919]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">86, dr[0.274,3.053], df[0.255,3.235], g[0.405,3.361]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">87, dr[0.411,2.780], df[0.513,4.270], g[0.491,3.288]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">88, dr[0.119,2.704], df[0.157,3.092], g[0.557,3.269]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">89, dr[0.394,3.857], df[0.472,3.342], g[0.379,3.062]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">90, dr[0.363,3.146], df[0.428,3.552], g[0.403,2.880]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">91, dr[0.152,3.319], df[0.519,4.014], g[0.426,3.380]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">92, dr[0.387,2.590], df[0.308,3.046], g[0.706,3.330]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">93, dr[0.251,3.265], df[0.314,2.769], g[0.875,3.106]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      ">94, dr[0.233,3.020], df[0.365,2.730], g[0.447,3.109]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">95, dr[0.293,3.471], df[0.241,3.297], g[0.478,3.043]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">96, dr[0.421,2.808], df[0.313,2.890], g[0.594,2.514]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      ">97, dr[0.233,2.869], df[0.225,2.848], g[0.341,3.210]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">98, dr[0.462,3.087], df[0.109,3.005], g[0.315,2.393]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">99, dr[0.362,3.245], df[0.325,2.745], g[0.312,2.933]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">100, dr[0.235,3.225], df[0.231,3.530], g[0.276,3.155]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">101, dr[0.198,2.439], df[0.352,2.933], g[0.344,3.390]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">102, dr[0.349,2.994], df[0.411,3.618], g[0.281,3.706]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      ">103, dr[0.149,4.020], df[0.164,2.603], g[0.283,3.289]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">104, dr[0.300,3.024], df[0.234,2.549], g[0.368,2.949]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      ">105, dr[0.200,3.267], df[0.411,3.541], g[0.263,3.611]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      ">106, dr[0.430,3.015], df[0.540,3.319], g[0.502,3.020]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      ">107, dr[0.270,2.621], df[0.176,3.232], g[0.279,3.488]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">108, dr[0.288,3.314], df[0.256,3.419], g[0.522,3.052]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">109, dr[0.378,3.837], df[0.136,3.384], g[0.143,3.353]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">110, dr[0.287,2.574], df[0.426,3.255], g[0.216,3.355]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">111, dr[0.093,2.747], df[0.239,2.558], g[0.231,2.777]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">112, dr[0.175,3.013], df[0.138,2.415], g[0.412,3.036]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      ">113, dr[0.285,3.198], df[0.144,2.226], g[0.396,3.635]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      ">114, dr[0.223,3.175], df[0.315,3.469], g[0.346,3.143]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">115, dr[0.171,2.784], df[0.229,3.640], g[0.355,3.153]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">116, dr[0.122,3.682], df[0.353,3.552], g[0.491,3.191]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">117, dr[0.179,2.602], df[0.097,2.734], g[0.218,3.074]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">118, dr[0.064,4.149], df[0.138,3.162], g[0.167,3.097]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">119, dr[0.109,2.832], df[0.290,3.331], g[0.338,2.543]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">120, dr[0.541,3.067], df[0.426,3.463], g[0.132,2.944]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      ">121, dr[0.312,2.581], df[0.317,3.553], g[0.378,3.236]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      ">122, dr[0.161,2.862], df[0.058,3.569], g[0.444,2.982]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">123, dr[0.430,3.494], df[0.416,3.299], g[0.174,3.263]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">124, dr[0.129,3.184], df[0.202,2.472], g[0.200,3.489]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">125, dr[0.186,2.479], df[0.066,3.139], g[0.148,3.024]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">126, dr[0.101,3.003], df[0.036,3.266], g[0.213,2.965]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">127, dr[0.261,3.156], df[0.180,2.991], g[0.221,3.433]\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      ">128, dr[0.170,4.606], df[0.235,3.712], g[0.149,3.411]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      ">129, dr[0.074,3.206], df[0.305,3.373], g[0.310,3.201]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      ">130, dr[0.066,3.712], df[0.126,3.212], g[0.390,3.350]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      ">131, dr[0.221,2.967], df[0.061,1.915], g[0.320,3.526]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      ">132, dr[0.132,3.908], df[0.410,3.427], g[0.101,3.096]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      ">133, dr[0.232,2.420], df[0.217,3.335], g[0.387,3.007]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      ">134, dr[0.311,3.375], df[0.307,3.713], g[0.270,3.484]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">135, dr[0.240,2.248], df[0.062,2.732], g[0.199,3.830]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">136, dr[0.217,4.083], df[0.204,2.727], g[0.352,3.361]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">137, dr[0.098,3.795], df[0.231,3.311], g[0.519,3.149]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">138, dr[0.424,2.709], df[0.203,3.292], g[0.220,3.271]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">139, dr[0.304,3.455], df[0.422,3.538], g[0.333,3.348]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">140, dr[0.097,3.346], df[0.168,4.225], g[0.486,3.599]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">141, dr[0.126,3.602], df[0.062,2.687], g[0.808,2.468]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">142, dr[0.507,3.339], df[0.397,3.280], g[0.331,3.201]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">143, dr[0.208,2.610], df[0.398,2.698], g[0.227,3.591]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">144, dr[0.212,2.843], df[0.184,3.525], g[0.283,3.132]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">145, dr[0.298,2.393], df[0.143,4.369], g[0.231,3.208]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">146, dr[0.181,3.516], df[0.445,3.166], g[0.177,2.628]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">147, dr[0.203,3.060], df[0.179,2.299], g[0.366,3.219]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">148, dr[0.042,3.639], df[0.054,2.580], g[0.386,3.390]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">149, dr[0.380,3.116], df[0.095,2.998], g[0.290,3.522]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">150, dr[0.268,3.039], df[0.106,2.656], g[0.188,3.435]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      ">151, dr[0.039,4.022], df[0.719,2.356], g[0.356,2.913]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      ">152, dr[0.315,3.399], df[0.057,2.763], g[0.344,3.176]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      ">153, dr[0.213,3.258], df[0.548,2.795], g[0.687,2.805]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">154, dr[0.458,3.399], df[0.060,4.132], g[0.270,3.059]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">155, dr[0.137,2.938], df[0.303,2.705], g[0.186,2.806]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">156, dr[0.090,2.691], df[0.063,3.684], g[0.379,3.447]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      ">157, dr[0.453,3.165], df[0.175,3.088], g[0.168,3.406]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      ">158, dr[0.141,3.106], df[0.440,2.870], g[0.314,3.552]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      ">159, dr[0.288,3.162], df[0.420,3.707], g[0.262,3.102]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      ">160, dr[0.238,2.635], df[0.135,3.487], g[0.437,3.717]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      ">161, dr[0.245,2.861], df[0.165,3.620], g[0.251,3.250]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      ">162, dr[0.094,2.846], df[0.262,3.308], g[0.371,2.733]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">163, dr[0.231,2.678], df[0.074,3.267], g[0.230,3.644]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">164, dr[0.165,3.856], df[0.192,3.360], g[0.218,3.400]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">165, dr[0.063,2.410], df[0.331,3.341], g[0.223,3.028]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      ">166, dr[0.162,3.032], df[0.211,2.968], g[0.439,2.766]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">167, dr[0.374,3.545], df[0.529,3.481], g[0.306,3.546]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">168, dr[0.124,3.774], df[0.367,3.468], g[0.318,3.202]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">169, dr[0.492,3.390], df[0.327,2.876], g[0.217,3.325]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">170, dr[0.176,3.459], df[0.560,3.271], g[0.684,3.025]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">171, dr[0.334,2.527], df[0.045,2.818], g[0.277,2.889]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">172, dr[0.143,3.634], df[0.382,3.989], g[0.697,3.058]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">173, dr[0.601,2.873], df[0.273,3.583], g[0.130,2.779]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">174, dr[0.068,3.128], df[0.280,2.039], g[0.365,2.679]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      ">175, dr[0.192,2.991], df[0.197,2.495], g[0.424,3.366]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      ">176, dr[0.125,3.400], df[0.178,3.380], g[0.270,3.225]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      ">177, dr[0.090,3.096], df[0.044,2.806], g[0.371,3.001]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      ">178, dr[0.699,2.739], df[0.978,3.106], g[0.465,3.406]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">179, dr[0.451,3.179], df[0.371,2.762], g[0.455,3.422]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">180, dr[0.483,3.607], df[0.239,3.828], g[0.109,3.449]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      ">181, dr[0.060,3.307], df[0.087,3.074], g[0.135,3.227]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">182, dr[0.091,2.646], df[0.173,3.312], g[0.479,2.794]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">183, dr[0.393,3.320], df[0.258,3.141], g[0.058,3.271]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      ">184, dr[0.087,3.118], df[0.373,3.043], g[0.544,3.489]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">185, dr[0.177,2.691], df[0.074,3.118], g[0.421,3.161]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">186, dr[0.811,3.227], df[0.410,3.334], g[0.223,3.266]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">187, dr[0.279,2.660], df[0.594,2.446], g[0.234,2.807]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">188, dr[0.281,3.396], df[0.203,3.470], g[0.327,3.392]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      ">189, dr[0.106,3.436], df[0.138,3.363], g[0.164,2.797]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      ">190, dr[0.212,3.233], df[0.530,2.545], g[0.641,3.055]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      ">191, dr[0.174,2.744], df[0.126,2.848], g[0.748,3.452]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">192, dr[0.254,3.915], df[0.132,2.505], g[0.266,3.291]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      ">193, dr[0.164,3.244], df[0.268,2.983], g[0.333,4.049]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      ">194, dr[0.258,2.843], df[0.376,2.697], g[0.543,3.880]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      ">195, dr[0.365,3.203], df[0.391,2.582], g[0.625,2.873]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">196, dr[0.443,2.685], df[0.764,3.668], g[0.755,2.726]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      ">197, dr[0.861,3.348], df[0.758,3.140], g[0.340,2.851]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">198, dr[0.664,3.071], df[0.397,3.785], g[0.592,3.030]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      ">199, dr[0.299,3.121], df[0.409,3.111], g[0.419,2.453]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      ">200, dr[0.245,3.796], df[0.244,2.782], g[1.168,2.867]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      ">201, dr[0.728,2.519], df[0.902,3.792], g[0.213,3.166]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">202, dr[0.053,3.007], df[0.425,2.853], g[1.404,3.593]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      ">203, dr[0.922,3.159], df[0.464,2.755], g[0.459,3.450]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">204, dr[0.088,3.203], df[0.377,3.618], g[0.902,3.064]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">205, dr[0.523,2.964], df[0.257,3.039], g[0.258,2.810]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">206, dr[0.121,3.402], df[0.439,3.344], g[0.616,3.087]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">207, dr[0.409,3.250], df[0.754,2.639], g[1.268,3.306]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">208, dr[1.461,3.597], df[1.154,3.288], g[0.720,2.829]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      ">209, dr[0.580,3.349], df[0.181,4.057], g[0.130,2.982]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      ">210, dr[0.190,3.430], df[0.641,2.781], g[0.821,3.320]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">211, dr[0.695,3.280], df[0.339,3.279], g[0.236,3.648]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      ">212, dr[0.238,3.131], df[0.594,3.026], g[0.915,3.199]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      ">213, dr[0.796,2.916], df[0.307,2.990], g[0.201,2.626]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">214, dr[0.132,2.753], df[0.361,2.754], g[0.583,2.873]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      ">215, dr[0.396,2.618], df[0.280,4.005], g[0.344,2.876]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">216, dr[0.143,3.545], df[0.652,3.524], g[1.089,3.221]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">217, dr[0.757,3.454], df[0.363,3.196], g[0.265,2.861]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">218, dr[0.284,3.425], df[0.461,2.849], g[0.351,2.882]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">219, dr[0.216,2.783], df[0.364,2.945], g[1.239,3.540]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      ">220, dr[0.631,3.477], df[0.694,3.530], g[0.613,3.062]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      ">221, dr[0.478,3.928], df[0.173,2.898], g[0.233,2.919]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">222, dr[0.184,3.206], df[0.438,3.537], g[0.521,3.510]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">223, dr[0.495,3.475], df[0.220,2.550], g[0.374,3.149]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">224, dr[0.228,2.855], df[0.992,2.807], g[1.493,2.871]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">225, dr[1.350,3.469], df[0.531,3.221], g[0.300,2.652]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      ">226, dr[0.081,2.908], df[0.789,2.537], g[1.101,2.972]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      ">227, dr[1.336,3.172], df[0.950,3.393], g[0.632,2.827]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">228, dr[0.379,3.901], df[0.715,2.744], g[0.878,2.853]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">229, dr[0.779,2.809], df[1.082,2.216], g[0.967,2.901]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">230, dr[0.560,2.883], df[0.317,2.710], g[0.590,3.066]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">231, dr[0.739,2.675], df[0.681,2.814], g[0.753,2.242]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">232, dr[0.496,3.157], df[0.382,3.070], g[0.427,2.618]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">233, dr[0.443,3.319], df[0.376,3.220], g[0.214,3.318]\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      ">234, dr[0.166,3.251], df[0.640,2.793], g[0.790,3.281]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">235, dr[1.005,4.134], df[0.801,4.254], g[0.763,3.276]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">236, dr[0.321,2.776], df[0.454,3.208], g[0.997,2.681]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">237, dr[0.516,2.855], df[0.649,3.174], g[1.480,2.733]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">238, dr[0.681,2.831], df[0.682,2.884], g[0.981,2.730]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">239, dr[0.604,2.957], df[0.263,2.586], g[0.908,3.043]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      ">240, dr[1.075,3.443], df[2.624,3.832], g[0.463,2.637]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      ">241, dr[0.542,3.493], df[1.229,2.411], g[3.317,3.397]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">242, dr[1.831,2.616], df[0.371,3.496], g[0.789,2.643]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">243, dr[0.663,3.087], df[1.810,3.561], g[1.212,3.122]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">244, dr[1.072,3.773], df[0.286,3.254], g[0.854,3.456]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">245, dr[1.027,2.524], df[1.102,3.932], g[0.481,3.672]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">246, dr[0.401,3.440], df[0.872,3.736], g[0.991,3.309]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">247, dr[1.167,3.804], df[0.962,3.122], g[1.258,4.054]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">248, dr[0.392,2.871], df[0.519,3.226], g[1.366,2.694]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ">249, dr[1.320,3.781], df[1.239,3.154], g[0.694,3.180]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      ">250, dr[0.295,3.206], df[0.356,2.483], g[0.852,3.270]\n"
     ]
    }
   ],
   "source": [
    "# define the standalone discriminator model\n",
    "def define_discriminator(in_shape=(28,28,1), n_classes=10):\n",
    "\t# weight initialization\n",
    "\tinit = RandomNormal(stddev=0.02)\n",
    "\t# image input\n",
    "\tin_image = Input(shape=in_shape)\n",
    "\t# downsample to 14x14\n",
    "\tfe = Conv2D(32, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(in_image)\n",
    "\tfe = LeakyReLU(alpha=0.2)(fe)\n",
    "\tfe = Dropout(0.5)(fe)\n",
    "\t# normal\n",
    "\tfe = Conv2D(64, (3,3), padding='same', kernel_initializer=init)(fe)\n",
    "\tfe = BatchNormalization()(fe)\n",
    "\tfe = LeakyReLU(alpha=0.2)(fe)\n",
    "\tfe = Dropout(0.5)(fe)\n",
    "\t# downsample to 7x7\n",
    "\tfe = Conv2D(128, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(fe)\n",
    "\tfe = BatchNormalization()(fe)\n",
    "\tfe = LeakyReLU(alpha=0.2)(fe)\n",
    "\tfe = Dropout(0.5)(fe)\n",
    "\t# normal\n",
    "\tfe = Conv2D(256, (3,3), padding='same', kernel_initializer=init)(fe)\n",
    "\tfe = BatchNormalization()(fe)\n",
    "\tfe = LeakyReLU(alpha=0.2)(fe)\n",
    "\tfe = Dropout(0.5)(fe)\n",
    "\t# flatten feature maps\n",
    "\tfe = Flatten()(fe)\n",
    "\t# real/fake output\n",
    "\tout1 = Dense(1, activation='sigmoid')(fe)\n",
    "\t# class label output\n",
    "\tout2 = Dense(n_classes, activation='softmax')(fe)\n",
    "\t# define model\n",
    "\tmodel = Model(in_image, [out1, out2])\n",
    "\t# compile model\n",
    "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
    "\tmodel.compile(loss=['binary_crossentropy', 'sparse_categorical_crossentropy'], optimizer=opt)\n",
    "\treturn model\n",
    "\n",
    "# define the standalone generator model\n",
    "def define_generator(latent_dim, n_classes=10):\n",
    "\t# weight initialization\n",
    "\tinit = RandomNormal(stddev=0.02)\n",
    "\t# label input\n",
    "\tin_label = Input(shape=(1,))\n",
    "\t# embedding for categorical input\n",
    "\tli = Embedding(n_classes, 50)(in_label)\n",
    "\t# linear multiplication\n",
    "\tn_nodes = 7 * 7\n",
    "\tli = Dense(n_nodes, kernel_initializer=init)(li)\n",
    "\t# reshape to additional channel\n",
    "\tli = Reshape((7, 7, 1))(li)\n",
    "\t# image generator input\n",
    "\tin_lat = Input(shape=(latent_dim,))\n",
    "\t# foundation for 7x7 image\n",
    "\tn_nodes = 384 * 7 * 7\n",
    "\tgen = Dense(n_nodes, kernel_initializer=init)(in_lat)\n",
    "\tgen = Activation('relu')(gen)\n",
    "\tgen = Reshape((7, 7, 384))(gen)\n",
    "\t# merge image gen and label input\n",
    "\tmerge = Concatenate()([gen, li])\n",
    "\t# upsample to 14x14\n",
    "\tgen = Conv2DTranspose(192, (5,5), strides=(2,2), padding='same', kernel_initializer=init)(merge)\n",
    "\tgen = BatchNormalization()(gen)\n",
    "\tgen = Activation('relu')(gen)\n",
    "\t# upsample to 28x28\n",
    "\tgen = Conv2DTranspose(1, (5,5), strides=(2,2), padding='same', kernel_initializer=init)(gen)\n",
    "\tout_layer = Activation('tanh')(gen)\n",
    "\t# define model\n",
    "\tmodel = Model([in_lat, in_label], out_layer)\n",
    "\treturn model\n",
    "\n",
    "# define the combined generator and discriminator model, for updating the generator\n",
    "def define_gan(g_model, d_model):\n",
    "\t# make weights in the discriminator not trainable\n",
    "\tfor layer in d_model.layers:\n",
    "\t\tif not isinstance(layer, BatchNormalization):\n",
    "\t\t\tlayer.trainable = False\n",
    "\t# connect the outputs of the generator to the inputs of the discriminator\n",
    "\tgan_output = d_model(g_model.output)\n",
    "\t# define gan model as taking noise and label and outputting real/fake and label outputs\n",
    "\tmodel = Model(g_model.input, gan_output)\n",
    "\t# compile model\n",
    "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
    "\tmodel.compile(loss=['binary_crossentropy', 'sparse_categorical_crossentropy'], optimizer=opt)\n",
    "\treturn model\n",
    "\n",
    "# load images\n",
    "# def load_real_samples():\n",
    "# \t# load dataset\n",
    "# \t(trainX, trainy), (_, _) = load_data()\n",
    "# \t# expand to 3d, e.g. add channels\n",
    "# \tX = expand_dims(trainX, axis=-1)\n",
    "# \t# convert from ints to floats\n",
    "# \tX = X.astype('float32')\n",
    "# \t# scale from [0,255] to [-1,1]\n",
    "# \tX = (X - 127.5) / 127.5\n",
    "# \tprint(X.shape, trainy.shape)\n",
    "# \treturn [X, trainy]\n",
    "\n",
    "# select real samples\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "\t# split into images and labels\n",
    "\timages, labels = dataset\n",
    "\t# choose random instances\n",
    "\tix = randint(0, images.shape[0], n_samples)\n",
    "\t# select images and labels\n",
    "\tX, labels = images[ix], labels[ix]\n",
    "\t# generate class labels\n",
    "\ty = ones((n_samples, 1))\n",
    "\treturn [X, labels], y\n",
    "\n",
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(latent_dim, n_samples, n_classes=10):\n",
    "\t# generate points in the latent space\n",
    "\tx_input = randn(latent_dim * n_samples)\n",
    "\t# reshape into a batch of inputs for the network\n",
    "\tz_input = x_input.reshape(n_samples, latent_dim)\n",
    "\t# generate labels\n",
    "\tlabels = randint(0, n_classes, n_samples)\n",
    "\treturn [z_input, labels]\n",
    "\n",
    "# use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "\t# generate points in latent space\n",
    "\tz_input, labels_input = generate_latent_points(latent_dim, n_samples)\n",
    "\t# predict outputs\n",
    "\timages = generator.predict([z_input, labels_input])\n",
    "\t# create class labels\n",
    "\ty = zeros((n_samples, 1))\n",
    "\treturn [images, labels_input], y\n",
    "\n",
    "# generate samples and save as a plot and save the model\n",
    "def summarize_performance(step, g_model, latent_dim, n_samples=100):\n",
    "\t# prepare fake examples\n",
    "\t[X, _], _ = generate_fake_samples(g_model, latent_dim, n_samples)\n",
    "\t# scale from [-1,1] to [0,1]\n",
    "\tX = (X + 1) / 2.0\n",
    "\t# plot images\n",
    "\tfor i in range(100):\n",
    "\t\t# define subplot\n",
    "\t\tpyplot.subplot(10, 10, 1 + i)\n",
    "\t\t# turn off axis\n",
    "\t\tpyplot.axis('off')\n",
    "\t\t# plot raw pixel data\n",
    "\t\tpyplot.imshow(X[i, :, :, 0], cmap='gray_r')\n",
    "\t# save plot to file\n",
    "\tfilename1 = 'results/ACGAN/generated_plot_%04d.png' % (step+1)\n",
    "\tpyplot.savefig(filename1)\n",
    "\tpyplot.close()\n",
    "\t# save the generator model\n",
    "\tfilename2 = 'results/ACGAN/model_%04d.h5' % (step+1)\n",
    "\tg_model.save(filename2)\n",
    "\tprint('>Saved: %s and %s' % (filename1, filename2))\n",
    "\n",
    "# train the generator and discriminator\n",
    "# def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100, n_batch=64):\n",
    "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=5, n_batch=20):\n",
    "\t# calculate the number of batches per training epoch\n",
    "\tbat_per_epo = int(dataset[0].shape[0] / n_batch)\n",
    "\t# calculate the number of training iterations\n",
    "\tn_steps = bat_per_epo * n_epochs\n",
    "\t# calculate the size of half a batch of samples\n",
    "\thalf_batch = int(n_batch / 2)\n",
    "\t# manually enumerate epochs\n",
    "\tfor i in range(n_steps):\n",
    "\t\t# get randomly selected 'real' samples\n",
    "\t\t[X_real, labels_real], y_real = generate_real_samples(dataset, half_batch)\n",
    "\t\t# update discriminator model weights\n",
    "\t\t_,d_r1,d_r2 = d_model.train_on_batch(X_real, [y_real, labels_real])\n",
    "\t\t# generate 'fake' examples\n",
    "\t\t[X_fake, labels_fake], y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "\t\t# update discriminator model weights\n",
    "\t\t_,d_f,d_f2 = d_model.train_on_batch(X_fake, [y_fake, labels_fake])\n",
    "\t\t# prepare points in latent space as input for the generator\n",
    "\t\t[z_input, z_labels] = generate_latent_points(latent_dim, n_batch)\n",
    "\t\t# create inverted labels for the fake samples\n",
    "\t\ty_gan = ones((n_batch, 1))\n",
    "\t\t# update the generator via the discriminator's error\n",
    "\t\t_,g_1,g_2 = gan_model.train_on_batch([z_input, z_labels], [y_gan, z_labels])\n",
    "\t\t# summarize loss on this batch\n",
    "\t\tprint('>%d, dr[%.3f,%.3f], df[%.3f,%.3f], g[%.3f,%.3f]' % (i+1, d_r1,d_r2, d_f,d_f2, g_1,g_2))\n",
    "\t\t# evaluate the model performance every 'epoch'\n",
    "\t\tif (i+1) % (bat_per_epo * 10) == 0:\n",
    "\t\t\tsummarize_performance(i, g_model, latent_dim)\n",
    "\n",
    "# make folder for results\n",
    "os.makedirs('results/ACGAN', exist_ok=True)\n",
    "# size of the latent space\n",
    "latent_dim = 100\n",
    "# create the discriminator\n",
    "discriminator = define_discriminator()\n",
    "# create the generator\n",
    "generator = define_generator(latent_dim)\n",
    "# create the gan\n",
    "gan_model = define_gan(generator, discriminator)\n",
    "# load image data\n",
    "dataset = load_real_samples()\n",
    "# train model\n",
    "train(generator, discriminator, gan_model, dataset, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "(12544, 10)\n"
     ]
    }
   ],
   "source": [
    "print(discriminator.get_weights()[23].shape)\n",
    "print(discriminator.get_weights()[22].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "input_1 <keras.engine.input_layer.InputLayer object at 0x000001EB2F8FD9A0>\n",
      "conv2d <keras.layers.convolutional.conv2d.Conv2D object at 0x000001EB2F924220>\n",
      "leaky_re_lu <keras.layers.activation.leaky_relu.LeakyReLU object at 0x000001EB2F9244F0>\n",
      "dropout <keras.layers.regularization.dropout.Dropout object at 0x000001EB2F9249A0>\n",
      "conv2d_1 <keras.layers.convolutional.conv2d.Conv2D object at 0x000001EB2F9B8F10>\n",
      "batch_normalization <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001EB2F924610>\n",
      "leaky_re_lu_1 <keras.layers.activation.leaky_relu.LeakyReLU object at 0x000001EB2FA188B0>\n",
      "dropout_1 <keras.layers.regularization.dropout.Dropout object at 0x000001EB2FA252E0>\n",
      "conv2d_2 <keras.layers.convolutional.conv2d.Conv2D object at 0x000001EB2FA3F610>\n",
      "batch_normalization_1 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001EB2FA3F340>\n",
      "leaky_re_lu_2 <keras.layers.activation.leaky_relu.LeakyReLU object at 0x000001EB2FA3F2B0>\n",
      "dropout_2 <keras.layers.regularization.dropout.Dropout object at 0x000001EB2FA4CFA0>\n",
      "conv2d_3 <keras.layers.convolutional.conv2d.Conv2D object at 0x000001EB2FA54BE0>\n",
      "batch_normalization_2 <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001EB2FA5B400>\n",
      "leaky_re_lu_3 <keras.layers.activation.leaky_relu.LeakyReLU object at 0x000001EB2FA5BD90>\n",
      "dropout_3 <keras.layers.regularization.dropout.Dropout object at 0x000001EB2FA63130>\n",
      "flatten <keras.layers.reshaping.flatten.Flatten object at 0x000001EB2FA69430>\n",
      "dense <keras.layers.core.dense.Dense object at 0x000001EB2FA69F70>\n",
      "dense_1 <keras.layers.core.dense.Dense object at 0x000001EB2FA63730>\n"
     ]
    }
   ],
   "source": [
    "print(len(discriminator.layers))\n",
    "for layer in discriminator.layers:\n",
    "    print(layer.name, layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "##### Neural Network model #####\n",
    "#################################\n",
    "import torch.nn as nn\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, channels=1, hideen=1, num_classes=10):\n",
    "        super(VGG, self).__init__()\n",
    "        self.body = nn.Sequential(\n",
    "            nn.Conv2d(channels, 32, kernel_size=(3,3), stride=(2,2), padding=1),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv2d(32, 64, kernel_size=(3,3), padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv2d(64, 128, kernel_size=(3,3), stride=(2,2), padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv2d(128, 256, kernel_size=(3,3), padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(12544, num_classes)\n",
    "            # nn.Linear(hideen, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.body(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 1, 3, 3)\n",
      "(64, 32, 3, 3)\n",
      "(128, 64, 3, 3)\n",
      "(256, 128, 3, 3)\n",
      "(12544, 10)\n"
     ]
    }
   ],
   "source": [
    "torch_model = torch.load(\"../pretrained/test_torch.pt\")\n",
    "torch_weights = torch_model.body.state_dict()\n",
    "# Reshape weights for Keras model\n",
    "keras_weights = [w.cpu().numpy() for w in torch_weights.values()]\n",
    "\n",
    "for i in [0, 2, 9, 16]:\n",
    "    print(keras_weights[i].shape)\n",
    "    # conv2d layer: Torch (out,in,h,w) Keras (h,w,in,out)\n",
    "    keras_weights[i] = np.moveaxis(keras_weights[i], [0,1], [-1,-2])\n",
    "keras_weights.append(torch_model.fc[0].weight.cpu().detach().numpy().T)\n",
    "print(keras_weights[len(keras_weights)-1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "968934d88acb7fa4003ed11a52074e68ba95c397f9757dc45b04b92654f10ea7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
